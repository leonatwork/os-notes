{"version":3,"sources":["components/header.jsx","components/index.jsx","components/notes.jsx","data/notes-object.js","components/content.jsx","components/main.jsx","index.js"],"names":["Header","state","navExpanded","navbarStyle","backgroundColor","navbarTextStyle","color","fontSize","fontFamily","this","props","showNav","Navbar","collapseOnSelect","style","expand","Brand","href","Toggle","aria-controls","Collapse","id","Nav","className","notes","map","note","activeNoteID","Link","key","onClick","handleClick","cursor","textAlign","title","Component","Index","Notes","Fragment","content","width","colSpan","Content","margin","paddingTop","borderRight","Main","showResponsiveNav","setState","currentShowNav","window","innerWidth","addEventListener","resize","bind","removeEventListener","ReactDOM","render","document","getElementById"],"mappings":"sQA6DeA,E,4MAxDbC,MAAQ,CAAEC,aAAa,G,uDACb,IAAD,OACDC,EAAc,CAClBC,gBAAiB,sBAEbC,EAAkB,CACtBC,MAAO,QACPC,SAAU,OACVC,WAAY,2BAEd,OAAIC,KAAKC,MAAMC,QAEX,kBAACC,EAAA,EAAD,CAAQC,kBAAgB,EAACC,MAAOX,EAAaY,OAAO,MAClD,kBAACH,EAAA,EAAOI,MAAR,CACEF,MAAOT,EACPY,KAAK,0CAFP,YAMA,kBAACL,EAAA,EAAOM,OAAR,CAAeC,gBAAc,qBAC7B,kBAACP,EAAA,EAAOQ,SAAR,CAAiBC,GAAG,oBAClB,kBAACC,EAAA,EAAD,CAAKC,UAAU,WACZd,KAAKC,MAAMc,MAAMC,KAAI,SAACC,GACrB,IAAIH,EAAY,kBAGhB,OAFIG,EAAKL,KAAO,EAAKX,MAAMiB,eACzBJ,GAAa,cAEb,kBAACD,EAAA,EAAIM,KAAL,CACEC,IAAKH,EAAKL,GACVJ,KAAM,IAAMS,EAAKL,GACjBE,UAAWA,EACXO,QAAS,kBAAM,EAAKpB,MAAMqB,YAAYL,EAAKL,KAC3CP,MAAO,CAAEkB,OAAQ,UAAWC,UAAW,WAEtCP,EAAKQ,aAUpB,kBAACtB,EAAA,EAAD,CAAQG,OAAO,KAAKD,MAAOX,GACzB,kBAACS,EAAA,EAAOI,MAAR,CACEC,KAAK,yCACLH,MAAOT,GAFT,iB,GA9Ca8B,aCmBNC,EArBD,SAAC,GAA0C,IAAxCZ,EAAuC,EAAvCA,MAAOG,EAAgC,EAAhCA,aAAcI,EAAkB,EAAlBA,YACpC,OACE,wBAAIR,UAAU,+BACXC,EAAMC,KAAI,SAACC,GACV,IAAIH,EAAY,kBAEhB,OADIG,EAAKL,KAAOM,IAAcJ,GAAa,WAEzC,wBACEM,IAAKH,EAAKL,GACVE,UAAWA,EACXO,QAAS,kBAAMC,EAAYL,EAAKL,KAChCP,MAAO,CAAEkB,OAAQ,YAEhBN,EAAKQ,YCTHG,EAJD,SAAC,GAAc,IAAZX,EAAW,EAAXA,KACf,OAAO,kBAAC,IAAMY,SAAP,KAAiBZ,ICDbF,EAAQ,CACnB,CACEH,GAAI,EACJa,MAAO,eACPK,QACE,6BACE,4CACA,6BACA,+CACA,4BACE,oGAGA,iIAIA,0FAEF,kFACA,4BACE,4BACE,0CADF,kDAGA,4BACE,+CADF,kDAIF,oCACA,4BACE,6CACA,2CAEF,8CACA,4BACE,kDACA,iDACA,qDACA,+CACA,kDACA,wDAEF,wCArCF,+CAsCE,4BACE,qHAIA,mHAIA,oEACA,0IAKF,yCACA,4BACE,mHAIA,+DACA,kFACA,2HAIA,uIAIA,kEACA,6LAhBF,gFAwBA,gNAKA,gDACA,4BACE,iDACA,iEACA,4DACA,wEACA,yEACA,6FACiE,IAAK,IADtE,WAEW,IAFX,aAKF,wCA/FF,6DAiGE,6BACA,6BACA,mDAnGF,mBAoGmB,IApGnB,iBAoGsC,IApGtC,uBAoG+D,IApG/D,gDAsGE,6BACA,6BACA,+CAxGF,kFA0GE,6BACA,6BACA,4CACA,4BACE,6FACA,0GAIA,4BACE,6CAEE,4BACE,qDAEE,4BACE,mHAIA,wGAQR,6CAEE,4BACE,+EACA,6EAGJ,8CAEE,4BACE,gGAIA,6IAIA,sGAIA,6FAOR,4CACA,4BACE,8DACA,kIAIA,8DACA,2JAIA,uEACA,4FAEF,6BACA,4DACA,4BACE,4BACE,wDADF,UAGA,4BACE,uDADF,8LAKE,4BACE,mHAIA,iHAIA,4FAGA,gIAON,6BACA,2CACA,4BACE,4BACE,kDACA,4BACE,sHAIA,0GAIA,uCACA,4EACA,oCACA,2CACA,sCACA,8HAMJ,4BACE,uCACA,4BACE,yEACA,oEACA,0FAGA,6FAGA,2DACA,sFACA,8DACA,gHAMJ,4BACE,kDACA,4BACE,2DACA,oIAIA,wEACA,8FAKJ,4BACE,4GAIA,4BACE,kFACA,gJAIA,oDAGJ,4BACE,iDACA,4BACE,8GAIA,8CACA,sDAEE,4BACE,gFACA,2DAGJ,yEAOZ,CACElB,GAAI,EACJa,MAAO,qBACPK,QACE,6BACE,kDACA,6BACA,yCACA,4BACE,qGAIA,2EACA,uFAEF,sCACA,4BACE,yCACA,yCAEF,gDAjBF,iCAkBE,6BACA,gDAnBF,6CAoBE,6BACA,6BACA,wEACA,yCACA,4BACE,4DACA,2CAEF,iIAIA,mDACA,4BACE,iDACA,mDACA,uGApCJ,2FA2CE,6BACA,iDA5CF,qEA8CE,6BACA,mDACA,4BACE,+CACA,0CACA,gDACA,4CACA,8CAEF,2CACA,4BACE,4BACE,+CADF,kDAIA,4BACE,iDADF,4DAIA,4BACE,iDADF,kDAIA,4BACE,8CADF,+DAIA,4BACE,sDADF,6EAIA,4BACE,8CADF,oGAKF,sDACA,iEACA,4BACE,oDACA,qDACA,gDAEF,6BACA,0CACA,4BACE,4BACE,oDACA,4BACE,8CACA,4BACE,8CADF,iFAIA,4BACE,0CADF,yGAIA,4BACE,6CADF,qGAIA,yEACA,8EAGJ,4BACE,kCACA,4BACE,2EACA,6FAGA,sEACA,6FAGA,oKAOJ,4BACE,kDACA,4BACE,kEACA,oDAEE,4BACE,4BACE,oDADF,kHAKA,4BACE,oDADF,+DAMJ,oGAIA,mIAMJ,4BACE,0CACA,4BACE,2EACA,yDACA,8EACA,0EACA,4FAGA,kFACA,6GAIA,8FAGA,oFAGJ,4BACE,0DACA,4BACE,uFACA,wHAIA,iEACA,2KAKA,wOAMA,qDAGJ,4BACE,wDACA,4BACE,iEACA,oGAIA,sGAIA,sJAON,6BACA,iDACA,4BACE,qEACA,4BACE,4BACE,iDADF,uFAIA,4BACE,kDADF,uDAMJ,+CACA,4BACE,4BACE,0DADF,kJAKA,4BACE,yDADF,0DAKF,kEACA,4BACE,qEACA,4HAIA,iFACA,0EAEF,gDACA,4BACE,uGAIA,+EAEE,4BACE,6GAIA,wFAGJ,0HAIA,mFACA,+DAEF,mDAzRF,gJA4RE,4BACE,4BACE,8CADF,gGAIA,4BACE,8CADF,oEAKF,gDAtSF,gFAwSE,6BAxSF,uBA0SE,4BACE,4BACE,+CADF,4FAKA,4BACE,gDADF,kEAKF,4FAIN,CACElB,GAAI,EACJa,MAAO,eACPK,QACE,6BACE,4CACA,6BACA,4BACE,wFACA,mHAIA,6MAKA,0DAEE,4BACE,+CACA,8GAIA,+EAIN,6BACA,qDACA,4BACE,4BACE,8CACA,4BACE,4EACA,kHAIA,iEACA,8HAIA,6DACA,uDACA,iGAKJ,4BACE,gDACA,4BACE,yEACA,6FAKJ,4BACE,kDACA,4BACE,yDACA,wEACA,4EACA,uEACA,yDACA,+FAKJ,4BACE,sDACA,4BACE,qEACA,iFACA,mGAMJ,4BACE,4CACA,4BACE,uEAEE,4BACE,8CAEE,4BACE,gEACA,qDAGJ,4CAEE,4BACE,2CACA,mGAUZ,4BACE,yCACA,4BACE,mEACA,0EAIN,6BACA,mDACA,4BACE,+DACA,0EACA,4EACA,8HAIA,+FAKR,CACElB,GAAI,EACJa,MAAO,eACPK,QACE,6BACE,4CACA,6BACA,4BACE,wDACA,iGAGA,uEACA,+FAGA,kGAIF,2BACE,wCADF,gCAEE,6BACA,2CAHF,mCAKA,wNAKA,6BACA,oDACA,4BACE,4BACE,qCACA,4BACE,wDAGJ,4BACE,mDACA,4BACE,kEAGJ,4BACE,0CACA,4BACE,mHAIA,mDACA,0FAGJ,4BACE,sCACA,4BACE,0DACA,2CACA,wGAMJ,4BACE,8CACA,4BACE,iIAIA,0GAIA,4BACE,+CACA,2BACEhB,UAAU,gCACVT,MAAO,CAAEmB,UAAW,SAAUO,MAAO,UAErC,+BACE,4BACE,0CAEF,4BACE,uCAEF,4BACE,4CAKR,4BACE,2CACA,2BACEjB,UAAU,gCACVT,MAAO,CAAEmB,UAAW,SAAUO,MAAO,UAErC,+BACE,4BACE,yCACA,yCACA,0CAEF,4BACE,sCACA,sCACA,uCAEF,4BACE,oCACA,oCACA,qCAEF,4BACE,wBAAIC,QAAQ,KAAZ,sBAEF,4BACE,wCACA,wCACA,iDAWpB,CACEpB,GAAI,EACJa,MAAO,qBACPK,QACE,6BACE,kDACA,6BACA,yCAHF,iBAIE,6BACA,yCALF,gBAME,6BACA,6BAPF,mDASE,6BATF,6DAWE,6BAXF,qDAaE,6BACA,6BACA,sDACA,4BACE,kDACA,gEACA,uDACA,mCACA,uDACA,oDAtBJ,8CAyBE,6BACA,6BACA,sCACA,4BACE,8DACA,mHA9BJ,oBAoCE,4BACE,+CACA,qCACA,6CAEF,6CACA,4BACE,mCACA,uCACA,uCACA,qCACA,2CA/CJ,+DAkDE,6BACA,2DAnDF,iCAqDE,4BACE,6CACA,+CACA,8CAEF,2BACEhB,UAAU,gCACVT,MAAO,CAAEmB,UAAW,SAAUO,MAAO,UAErC,+BACE,4BACE,8CAEF,4BACE,+CAEF,4BACE,gDAEF,4BACE,yCAEF,4BACE,8CAEF,4BACE,mDAEF,4BACE,0CAlFR,4CAuFE,6BACA,6BACA,gDACA,4BACE,4BACE,0CADF,gDAEE,4CAFF,gLAKE,6CALF,iDA3FJ,kCAoGE,4BACE,kFACA,0EACA,2EAEF,wCACA,4BACE,4BACE,kEACA,4BACE,uIAMJ,4BACE,mEACA,4BACE,kMAvHR,0GAiIE,6BACA,6BACA,oDAnIF,2BAoIE,6BACA,oDArIF,yCAsIE,6BAtIF,2EAwIE,6BACA,6BACA,6CACA,4BACE,oGAGA,6EAEF,mCACA,4BACE,4BACE,qCADF,qCAEE,qCAFF,2FAnJJ,yFA2JE,6BACA,iEACA,8CACA,4BACE,sCACU,IADV,YACwB,IADxB,UAGA,yEACA,sEACA,kFACA,wEACA,qCACA,4BACE,uCAAa,IAAb,aACA,mFACA,+DAEF,uCACA,4BACE,uCACW,IADX,qBACkC,IADlC,aAGA,8DAEF,6BACA,wCACA,4BACE,8FAIF,yCACA,4BACE,sFAEF,6BACA,yDACA,4BACE,yEACA,2EAEF,kDACA,4BACE,kFACA,6GAKF,8CACA,4BACE,4BACE,+CACA,4BACE,oFACA,4FAKJ,4BACE,oDACA,4BACE,6EACA,6FA7DR,uDAoEE,6BACA,6BACA,2CAtEF,kDAuEE,4BACE,2HAIA,oGAIA,8GAMJ,4CACA,4BACE,sCACU,IADV,mBAC+B,IAD/B,UAGA,yDACA,iGAIF,oEACA,4BACE,4BACE,qCACA,4BACE,sEACA,kFACA,gIAIA,qFACyD,IADzD,SAGA,gEACA,8DAGJ,4BACE,kCACA,4BACE,mHAIA,yHAIA,gEACA,8FAGA,+HAIA,4JAIA,8HAIA,iMAKA,4BACE,wDACA,4BACE,yFAGA,2FAKJ,4BACE,oCACA,4BACE,iEACA,8EACA,6EACA,oEACA,yHAIA,6EAKR,4BACE,oCAGJ,uCA/UF,0CAgVE,4BACE,4BACE,+EACA,4BACE,0FAGA,uDACA,8GAMJ,4BACE,yCACA,4BACE,iEACA,gFACA,+EAIN,6BACA,0DACA,uCAzWF,qEA2WE,4BACE,sEACA,gIAIA,mDACA,gGAGA,4HAIA,iHAIA,yGAKF,2BACEjB,UAAU,gCACVT,MAAO,CAAEmB,UAAW,SAAUO,MAAO,UAErC,+BACE,4BACE,kCACA,kCACA,mCAEF,4BACE,yCACA,yCACA,0CAEF,4BACE,qCACA,qCACA,sCAEF,4BACE,wBAAIC,QAAQ,KAAZ,0BAIN,iDACA,4BACE,4BACE,iDACA,4BACE,yEACA,iEACA,uFACA,qKAOJ,4BACE,mDACA,4BACE,iEACA,2DACA,mJAON,oFAEE,6BAFF,+BAIE,6BAJF,yGAQA,0DACA,4BACE,8CACA,gDACA,oFACA,4CAEF,4CACA,4BACE,4BACE,0CACA,4BACE,mFACA,oFACA,qFACA,2FAGJ,4BACE,yCACA,4BACE,+EACA,kHAIA,kFACA,mIAMJ,4BACE,2CACA,4BACE,4GAIA,mDACA,+HAON,oDA9eF,+CA+eE,4BACE,4BACE,wDACA,4BACE,mEACA,mFAGJ,4BACE,oDACA,4BACE,8FAMN,iDAhgBF,2DAkgBE,4BACE,4BACE,iDACA,4BACE,kGAKJ,4BACE,kDACA,4BACE,4FAZN,+BAkBE,4BACE,2DACA,wEAGJ,2CACA,4BACE,uHAIA,yGAIA,6EACA,wCAEE,4BACE,gGAGA,+GAON,mDACA,4BACE,0LAKA,gIAIA,mGAOR,CACEpB,GAAI,EACJa,MAAO,0BACPK,QACE,6BACE,uDACA,6BACA,kDACA,4BACE,0FACA,mJAIA,+FAGA,kHAKF,gDAlBF,2FAoBE,6BACA,6BACA,+CACA,4BACE,6IAIA,8EACA,gGAGA,oIAIA,2EACA,kDAEF,kFACA,4BACE,4BACE,iDADF,eAEE,4BACE,8EAGJ,4BACE,yCADF,eAEE,4BACE,4LAKA,8HAMJ,4BACE,iDADF,aAEE,4BACE,qPASN,gDACA,4BACE,4BACE,qDACA,4BACE,0DACA,iJAOJ,4BACE,4DACA,4BACE,0DACA,kHAIA,wHAMJ,4BACE,kDACA,4BACE,gEACA,wGAIA,gGAMN,kDACA,4BACE,4FACA,oDACA,6GAIA,kEAEE,4BACE,uCAEE,4BACE,+FAMJ,8CAEE,4BACE,uHAIA,6DACgC,kCADhC,kBAQV,iDACA,4BACE,4BACE,oCACA,4BACE,6DACA,kGAIA,4BACE,yCACA,4BACE,wLAKA,iJAGE,6BACA,6BAJF,UAKU,KACR,6BANF,UAOU,IAPV,OAQE,6BARF,QASE,6BACC,IACD,6BACA,6BAZF,YAaY,KACV,6BAdF,OAgBE,6BACC,KAvBL,YA0BE,4BACE,4BACE,yCADF,iJAKA,4BACE,uCADF,kCAIF,wDACA,gCACK,KACH,6BAFF,eAIE,6BAJF,mBAME,6BANF,iBAQE,6BACC,IATH,iBAWA,2CACA,4BACE,iJAIA,qDACA,6HAKF,wCACA,4BACE,0HAON,oGAIA,4BACE,0CADF,2IAKA,4BACE,4CADF,0DAIA,4BACE,oDADF,iGAON,kEACA,4BACE,4BACE,qDACA,4BACE,6FAGA,oGAIA,wGAMJ,4BACE,sDACA,4BACE,mFACA,4EACA,+DACA,wEACA,4EACA,4EAGJ,4BACE,yDACA,4BACE,8DACA,iEACA,uDACA,6GAIA,kEACA,iDACA,2JAIA,2DA5CN,6CAiDA,uCACA,4BACE,6IAIA,yFACA,qKAIA,oJAKF,2CA5TF,6CA6TE,6BACA,4CA9TF,wFAgUE,6BACA,gDAjUF,2DAmUE,6BACA,6BApUF,gBAsUE,2BACEhB,UAAU,gCACVT,MAAO,CAAEmB,UAAW,SAAUO,MAAO,UAErC,+BACE,4BACE,kCACA,mCAEF,4BACE,sCACA,8BAEF,4BACE,uCACA,8BAEF,4BACE,6BAEA,wCAEF,4BACE,6BACA,yCAIN,2BACE,mDADF,4BAEE,6BAFF,6FAlWF,gBAyWE,2BACEjB,UAAU,gCACVT,MAAO,CAAEmB,UAAW,SAAUO,MAAO,UAErC,+BACE,4BACE,kCACA,mCAEF,4BACE,sCACA,8BAEF,4BACE,wCACA,wCAEF,4BACE,wCACA,wCAEF,4BACE,6BACA,wCAEF,4BACE,6BACA,yCApYR,OAwYM,kCAxYN,SAwYwB,kCAxYxB,wIA2YE,6BACA,6BA5YF,gHA8YE,6BACA,6BACA,iDACA,4BACE,4BACE,8CACA,6BAFF,4FAKE,4BACE,gDACA,mEACA,yCACA,0CAEF,2CACA,4BACE,0FAEF,iDACA,4BACE,yDACA,gEAIN,0CACA,4BACE,yKAQR,CACEnB,GAAI,EACJa,MAAO,YACPK,QACE,6BACE,yCACA,6BACA,gLAKA,mDARF,6EAUE,4BACE,4BACE,+CACA,4BACE,mIAMJ,4BACE,4CACA,4BACE,uIAMJ,4BACE,6CACA,4BACE,0FAGJ,4BACE,4CACA,4BACE,0JA5BN,sDAoCA,wDACA,4BACE,8HAIA,+CAAqB,IAArB,MACA,kDAAwB,IAAxB,MACA,wEACA,+FAEE,4BACE,oFACA,sGAON,8DACA,4BACE,0EACA,gGAGA,wFAEF,wDACA,4BACE,0CACA,yCACA,sDACA,yDAEF,8CACA,4BACE,4BACE,qDADF,0DAIA,4BACE,oDADF,8HAMF,6BACA,mDACA,+CACA,4BACE,mHAIA,iEAEF,4CACA,4BACE,4BACE,4CADF,wIAKA,4BACE,sDADF,0KAKA,4BACE,6CADF,uGAGE,4BACE,8GAIA,iHAON,4CACA,4BACE,oDACA,4BACE,oCADF,yPAMA,4BACE,oCADF,oMAOF,4CACA,4BACE,kKAIA,oJAKF,yCACA,4BACE,yIAIA,uGAEM,kCAFN,wBAEuC,kCAFvC,WAE4D,IAF5D,uEAMF,kEACA,4BACE,yDAC4B,kCAD5B,IAC0C,IAD1C,IAC+C,kCAAa,IAD5D,iBAEgB,kCAFhB,iBAE0C,mCAE1C,+EACA,2FACA,gFACA,0LAMF,yEACA,4BACE,+GAIA,iJAIA,+CAEE,4BACE,uFACA,2FAGA,wFAGJ,yFACA,+FAGA,2FACA,4CAEE,4BACE,iFACA,gEACA,uFACA,mHAON,6BACA,kDACA,4BACE,0GAIA,4BACE,oCADF,6CAGA,4BACE,uCADF,0GAxOJ,2CA8OE,4BACE,2DAEE,4BACE,mDACA,gCACG,kCADH,IACiB,IADjB,IACsB,kCADtB,MACqC,kCADrC,oBAEE,kCAFF,KAIA,8EAvPR,0CA4PE,4BACE,6DACA,oGAGE,4BACE,uGAIA,gHAIA,wHAE4B,IAF5B,KAEkC,kCAFlC,sCAGyB,sCA7QjC,sGAoRE,6BApRF,gBAsRE,4BACE,0DACA,sDAEF,kDACA,4BACE,gEACA,gFACA,6IAQR,CACElB,GAAI,EACJa,MAAO,oBACPK,QACE,6BACE,iDACA,6BACA,4BACE,2GAIA,2GAIA,kFACA,sHAIA,6FAEF,6CACA,4BACE,8FAGA,wEACA,mEACA,4EACA,iGAGA,4GAIA,8FAEE,6BAFF,mDAIE,6BAJF,8DAOF,8CACA,4BACE,oFACA,4HAIA,+EACA,6EACA,gGAGA,8GAKF,0DACA,4BACE,4BACE,2CACA,4BACE,gGAGA,mFAGJ,4BACE,wCACA,4BACE,4EACA,wEAGJ,4BACE,6CACA,4BACE,gHAIA,oFAIN,2BACE,gDADF,qBAEE,6BACA,iDAHF,oFAMA,4BACE,qIAIA,2HAKF,2BACE,sDADF,sGAGE,6BACA,uDAJF,oIAvGF,mBA+GmB,IA/GnB,kDAgHE,6BACA,4DACA,4BACE,mHAIA,2JAIA,4GA3HJ,iEAiIE,6BACA,6BACA,8CACA,4BACE,wEACA,uOAKA,sEAEF,6CACA,4BACE,iKAKF,8CACA,4BACE,qEAEF,sCAxJF,kEA0JE,4BACE,4FACA,iGAGA,mHAIA,sHAKF,oNAKA,uCACA,4BACE,oGAGA,gJAIA,0DAEF,yCACA,4BACE,wEACA,0EACA,0FACA,sFACA,sFACA,kFACA,+IAIA,oCACQ,IADR,uBACiC,IADjC,kBAIF,6BACA,iDACA,4BACE,4BACE,yCADF,kCAEE,4BACE,4BACE,sDACA,4BACE,wFAGA,mGAIA,mEACA,8DACA,sFAGA,4FAGA,4CACA,wDAGJ,4BACE,yDACA,4BACE,sGAIA,oEACA,wGAIA,mFACA,kEAEF,yCACA,4BACE,4BACE,wCADF,uBAEE,4BACE,8EAGJ,4BACE,uCACA,4BACE,8EAGJ,4BACE,wCADF,8BAEE,4BACE,4DAhCR,wDAuCF,4CACA,4BACE,4BACE,qDADF,sBAEE,4BACE,iIAMJ,4BACE,qDACA,4BACE,+KAOJ,4BACE,oDACA,4BACE,sFAGA,2NAMA,6DACA,iJAIA,4KASR,4BACE,6CACA,4BACE,6DACA,qCACA,4BACE,2GAIA,6FAGA,0FAGA,6BACA,qGAIA,+IAIA,6BACA,6IAIA,6BACA,8FAGA,+FAIA,4FAEE,4BACE,qEACA,6CAGJ,0GAIA,uEACA,uFACA,8FAGA,uMAKA,+EACA,uFAEE,mCAEF,6BACA,6GAIA,4JAKA,6BACA,+FAIA,kGAIA,yFAGA,gFACA,uHAIA,mFACA,0IAIA,iLAKA,+HAIA,iFACA,6BACA,uGAEY,6BAFZ,IAEmB,mCAFnB,WAEwC,mCAFxC,WAGE,mCAHF,WAGuB,mCAHvB,WAG4C,mCAH5C,WAOJ,yCACA,4BACE,+FAGA,iEACA,qIAIA,4FAGA,uGAKF,2CACA,4BACE,mEACA,0EACA,4FAIF,sDACA,4BACE,4BACE,sDACA,4BACE,8DACA,wIAIA,iDACqB,IADrB,sBAC6C,IAD7C,aAKJ,4BACE,gDACA,4BACE,0HAIA,yDAC6B,IAC3B,4BACE,mDACA,0DACA,gFAGJ,oMAOJ,4BACE,kDACA,4BACE,sEACA,4KAKA,kLAOJ,yCACA,4BACE,+FAIA,iEACA,qIAIA,4FAGA,uGAKF,2CACA,4BACE,mEACA,0EACA,4FAIF,sDACA,4BACE,4BACE,sDACA,4BACE,8DACA,wIAIA,iDACqB,IADrB,sBAC6C,IAD7C,aAKJ,4BACE,gDACA,4BACE,0HAIA,yDAC6B,IAC3B,4BACE,mDACA,0DACA,gFAGJ,oMAOJ,4BACE,kDACA,4BACE,sEACA,4KAKA,oLASR,2CACA,4BACE,gGAGA,mFACA,wFACA,wGAIA,+HAIA,iGASZ,CACElB,GAAI,EACJa,MAAO,kBACPK,QACE,6BACE,+CACA,6BACA,2BACE,8CADF,wIAKA,4BACE,+DACA,yDACA,kEACA,oEACA,gEAEF,2BACE,0CADF,4DAIA,6BACA,qDACA,4BACE,4BACE,mCACA,4BACE,6CAGJ,4BACE,+DACA,4BACE,+DACA,2DACA,+EACA,6GAMJ,4BACE,wDACA,4BACE,yHAIA,2FAGA,6CACA,sFAGJ,4BACE,oDACA,4BACE,yHAIA,yHAIA,2DACA,4DAGJ,4BACE,mCACA,4BACE,+HAIA,gDACA,oEAGJ,4BACE,oDACA,4BACE,4CACA,kEACA,8GAIA,sFACA,mECl1FCG,EA1BC,SAAC,GAA4C,IAA1Cf,EAAyC,EAAzCA,aAAchB,EAA2B,EAA3BA,QAASoB,EAAkB,EAAlBA,YACxC,OACE,yBACER,UAAU,MACVT,MACEH,EACI,CAAE6B,MAAO,OAAQG,OAAQ,SAAUC,WAAY,QAC/C,CAAEJ,MAAO,MAAOG,OAAQ,SAAUC,WAAY,UAGlDjC,GACA,yBAAKY,UAAU,QAAQT,MAAO,CAAE+B,YAAa,mBAC3C,kBAAC,EAAD,CACErB,MAAOA,EACPG,aAAcA,EACdI,YAAaA,KAInB,yBAAKR,UAAU,OACb,kBAAC,EAAD,CAAOG,KAAMF,EAAMG,GAAcY,aCoB1BO,E,4MAvCb7C,MAAQ,CAAE8C,mBAAmB,EAAOpB,aAAc,G,EAgBlDI,YAAc,SAACV,GACb,EAAK2B,SAAS,CAAErB,aAAcN,K,uDAf9B,IAAI4B,EAAiBC,OAAOC,WAAa,IACrCF,IAAmBxC,KAAKR,MAAMU,SAChCF,KAAKuC,SAAS,CAAED,kBAAmBE,M,0CAIrCC,OAAOE,iBAAiB,SAAU3C,KAAK4C,OAAOC,KAAK7C,OACnDA,KAAK4C,W,6CAILH,OAAOK,oBAAoB,SAAU9C,KAAK4C,OAAOC,KAAK7C,S,+BAQtD,OACE,6BACE,kBAAC,EAAD,CACEE,QAASF,KAAKR,MAAM8C,kBACpBvB,MAAOA,EACPG,aAAclB,KAAKR,MAAM0B,aACzBI,YAAatB,KAAKsB,cAEpB,kBAAC,EAAD,CACEpB,QAASF,KAAKR,MAAM8C,kBACpBpB,aAAclB,KAAKR,MAAM0B,aACzBI,YAAatB,KAAKsB,mB,GAjCTI,a,MCCnBqB,IAASC,OAAO,kBAAC,EAAD,MAAUC,SAASC,eAAe,W","file":"static/js/main.cbeb04b1.chunk.js","sourcesContent":["import React, { Component } from \"react\";\nimport Navbar from \"react-bootstrap/Navbar\";\nimport Nav from \"react-bootstrap/Nav\";\n\nclass Header extends Component {\n  state = { navExpanded: false };\n  render() {\n    const navbarStyle = {\n      backgroundColor: \"rgb(156, 220, 164)\",\n    };\n    const navbarTextStyle = {\n      color: \"white\",\n      fontSize: \"28px\",\n      fontFamily: \"'Merienda One', cursive\",\n    };\n    if (this.props.showNav) {\n      return (\n        <Navbar collapseOnSelect style={navbarStyle} expand=\"lg\">\n          <Navbar.Brand\n            style={navbarTextStyle}\n            href=\"https://leonatwork.github.io/os-notes/\"\n          >\n            OS Notes\n          </Navbar.Brand>\n          <Navbar.Toggle aria-controls=\"basic-navbar-nav\" />\n          <Navbar.Collapse id=\"basic-navbar-nav\">\n            <Nav className=\"mr-auto\">\n              {this.props.notes.map((note) => {\n                let className = \"list-group-item\";\n                if (note.id === this.props.activeNoteID)\n                  className += \" active-me\";\n                return (\n                  <Nav.Link\n                    key={note.id}\n                    href={\"#\" + note.id}\n                    className={className}\n                    onClick={() => this.props.handleClick(note.id)}\n                    style={{ cursor: \"pointer\", textAlign: \"center\" }}\n                  >\n                    {note.title}\n                  </Nav.Link>\n                );\n              })}\n            </Nav>\n          </Navbar.Collapse>\n        </Navbar>\n      );\n    }\n    return (\n      <Navbar expand=\"lg\" style={navbarStyle}>\n        <Navbar.Brand\n          href=\"https://leonatwork.github.io/os-notes/\"\n          style={navbarTextStyle}\n        >\n          OS Notes\n        </Navbar.Brand>\n      </Navbar>\n    );\n  }\n}\n\nexport default Header;\n","import React from \"react\";\n\nconst Index = ({ notes, activeNoteID, handleClick }) => {\n  return (\n    <ul className=\"list-group list-group-flush\">\n      {notes.map((note) => {\n        let className = \"list-group-item\";\n        if (note.id === activeNoteID) className += \" active\";\n        return (\n          <li\n            key={note.id}\n            className={className}\n            onClick={() => handleClick(note.id)}\n            style={{ cursor: \"pointer\" }}\n          >\n            {note.title}\n          </li>\n        );\n      })}\n    </ul>\n  );\n};\n\nexport default Index;\n","import React from \"react\";\n\nconst Notes = ({ note }) => {\n  return <React.Fragment>{note}</React.Fragment>;\n};\n\nexport default Notes;\n","import React from \"react\";\n\nexport const notes = [\n  {\n    id: 0,\n    title: \"Introduction\",\n    content: (\n      <div>\n        <h1>Introduction</h1>\n        <hr />\n        <b>Operating System</b>\n        <ul>\n          <li>\n            System software that acts as an interface between user and hardware.\n          </li>\n          <li>\n            OS manages computer hardware (controls and coordinates hardware\n            among various programs and users)\n          </li>\n          <li>Provides environment within which other programs can work</li>\n        </ul>\n        <b>Other than kernel there are two types of softwares:</b>\n        <ul>\n          <li>\n            <b>System SW :</b> associated with OS but not part of the kernel\n          </li>\n          <li>\n            <b>Application SW :</b> includes all programs not associated with OS\n          </li>\n        </ul>\n        <b>Goals</b>\n        <ul>\n          <li>User friendly</li>\n          <li>Efficiency</li>\n        </ul>\n        <b>Functions of OS</b>\n        <ul>\n          <li>Process management</li>\n          <li>Memory management</li>\n          <li>I/O device management</li>\n          <li>File management</li>\n          <li>Network management</li>\n          <li>Security and protection</li>\n        </ul>\n        <b>Booting :</b> starting the computer by loading the kernel\n        <ul>\n          <li>\n            Initial program or bootstrap program runs at boot time. This program\n            should be simple\n          </li>\n          <li>\n            It is stored in ROM or EEPROM and is known as firmware within the\n            computer hardware\n          </li>\n          <li>It initializes all aspects of system</li>\n          <li>\n            Bootstrap must know how to load the OS. For this bootstrap must\n            locate and load the OS kernel into memory\n          </li>\n        </ul>\n        <b>Interrupts</b>\n        <ul>\n          <li>\n            Occurrence of an event is signaled by an interrupt from either\n            hardware or software\n          </li>\n          <li>Modern OSs are interrupt driven</li>\n          <li>HW trigger an interrupt by sending a signal to CPU</li>\n          <li>\n            SW trigger an interrupt by executing a special operation called\n            system call or monitor call\n          </li>\n          <li>\n            Number of interrupts are predefined. A table of pointers to\n            interrupt routine is used to increase speed\n          </li>\n          <li>This table is stored in low memory</li>\n          <li>\n            Table keeps address of ISR for various devices. This array or\n            interrupt vector is indexed by a unique device number. This number\n            is provided with the request\n          </li>\n          Trap is a SW generated interrupt caused by an error/request from the\n          program\n        </ul>\n        <p>\n          CPU is connected to device via device controller. CPU and device\n          controller can execute concurrently competing for memory cycles.\n          Memory controller synchronizes access to memory\n        </p>\n        <b>Storage structure</b>\n        <ul>\n          <li>RAM (Main Memory)</li>\n          <li>Programs execute from Main memory</li>\n          <li>Use load and store operation</li>\n          <li>Load : main memory to internal registers</li>\n          <li>Store : internal registers to main memory</li>\n          <li>\n            Instruction execution cycle (von Neumann Architecture) Fetch -{\">\"}{\" \"}\n            Decode -{\">\"} Execute\n          </li>\n        </ul>\n        <b>Caching :</b> copying information to faster storage system\n        temporarily.\n        <br />\n        <br />\n        <b>Storage hierarchy : </b>\n        register(CMOS) -{\">\"} cache(SRAM) -{\">\"} main memory(DRAM) -{\">\"} disk\n        storage/secondary memory(Magnetic disk)\n        <br />\n        <br />\n        <b>Virtual memory :</b> a technique in which a program larger than size\n        of main memory can be executed\n        <br />\n        <br />\n        <b>I/O structure</b>\n        <ul>\n          <li>Each device controller is incharge of specific kind of device</li>\n          <li>\n            Device controller have buffer storage and set of special purpose\n            registers\n          </li>\n          <ul>\n            <li>\n              I/O interrupts\n              <ul>\n                <li>\n                  Starting IO operations\n                  <ul>\n                    <li>\n                      CPU loads appropriate registers in device controller based\n                      on which dc takes action\n                    </li>\n                    <li>\n                      Once complete the dc lets it known to CPU by triggering an\n                      interrupt\n                    </li>\n                  </ul>\n                </li>\n              </ul>\n            </li>\n            <li>\n              Synchronous IO\n              <ul>\n                <li>Control returned to IO process at IO completion</li>\n                <li>Till then process is moved to waiting phase</li>\n              </ul>\n            </li>\n            <li>\n              Asynchronous IO\n              <ul>\n                <li>\n                  Control returned to IO process without waiting for IO\n                  completion\n                </li>\n                <li>\n                  Device status table is used to keep track of IO devices. Table\n                  entry tells (device's type, address and state)\n                </li>\n                <li>\n                  If other process requests the busy device then it is put in\n                  wait queue\n                </li>\n                <li>\n                  On completion interrupt is triggered and table is updated\n                </li>\n              </ul>\n            </li>\n          </ul>\n        </ul>\n        <b>DMA structure</b>\n        <ul>\n          <li>Used for high speed IO devices</li>\n          <li>\n            Device controller set DMA controller registers to use appropriate\n            source and destination addresses\n          </li>\n          <li>OS finds a buffer for transfer</li>\n          <li>\n            The device controller transfers a block of data directly to/from its\n            own buffer storage to memory without CPU intervention.\n          </li>\n          <li>CPU can perform other tasks during this</li>\n          <li>Once transfer is complete DMA controller interrupts the CPU</li>\n        </ul>\n        <hr />\n        <h4>Computer System Architecture</h4>\n        <ol>\n          <li>\n            <b>Single processor system :</b> 1 CPU\n          </li>\n          <li>\n            <b>Multi processor system :</b> Multiple processors sharing\n            resources like bus, clock, memory, peripherals... Adv is graceful\n            degradation - incase of failure some system available to respond,\n            but some slow down occurs.\n            <ul>\n              <li>\n                Tandem system : 2 identical processors (Primary+Backup) if\n                failure backup activated\n              </li>\n              <li>\n                SMP (Symmetric Multiprocessing system) - each processor runs\n                identical copy of OS\n              </li>\n              <li>\n                Asymmetric MP - each system assigned specific task by master\n              </li>\n              <li>\n                Cluster systems : multiple CPU on different systems coupled\n                together. Adv...high availability\n              </li>\n            </ul>\n          </li>\n        </ol>\n        <hr />\n        <h4>Types of OS</h4>\n        <ol>\n          <li>\n            <b>Batch processing OS</b>\n            <ul>\n              <li>\n                Jobs with similar needs are batched together and executed\n                through processor as a group\n              </li>\n              <li>\n                No memory hierarchy only one memory and os is present it it the\n                whole time\n              </li>\n              <li>One cpu</li>\n              <li>One operator who groups the job into batches</li>\n              <li>Slow</li>\n              <li>Inefficient</li>\n              <li>Oldest</li>\n              <li>\n                Better than previous design as grouping of jobs removed the time\n                needed for loading compiler\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>Spooling</b>\n            <ul>\n              <li>Simultaneous peripheral operations online</li>\n              <li>Additional disk memory is introduced</li>\n              <li>\n                Peripheral devices interact with disk directly and not cpu\n              </li>\n              <li>\n                Cpu only deals with main memory which in turn deals with disk\n              </li>\n              <li>Cpu utilization is improved</li>\n              <li>Multiple devices can interact with disk simultaneously</li>\n              <li>Interactive processes possible</li>\n              <li>\n                But dis adv is it is uniprogramming ie. cpu waits if process\n                needs for some io\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>Multiprogramming OS</b>\n            <ul>\n              <li>Goal is max cpu utilization</li>\n              <li>\n                Cpu doesn't wait if process waits for io, it executes another\n                ready process available in main memory\n              </li>\n              <li>Context switch between processes happens</li>\n              <li>\n                More complex management/fragmentation issues/paging required\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>\n              Multi tasking / time sharing / fair share / multiprogramming with\n              round robin\n            </b>\n            <ul>\n              <li>Multitasking is multiprogramming with time sharing</li>\n              <li>\n                Only one cpu, context switch between processes happen so fast\n                that it appears as if it is running simultaneously\n              </li>\n              <li>High response time</li>\n            </ul>\n          </li>\n          <li>\n            <b>Multiprocessing OS</b>\n            <ul>\n              <li>\n                2 or more CPUs in a single system, sharing memory, io devices\n                and system buses\n              </li>\n              <li>Truly parallel</li>\n              <li>\n                2 kinds of architecture\n                <ul>\n                  <li>Symmetric : all CPU same, managed by a single OS</li>\n                  <li>Asymmetric : master slave</li>\n                </ul>\n              </li>\n              <li>Increased throughput and reliability</li>\n            </ul>\n          </li>\n        </ol>\n      </div>\n    ),\n  },\n  {\n    id: 1,\n    title: \"Process Scheduling\",\n    content: (\n      <div>\n        <h1>Process Scheduling</h1>\n        <hr />\n        <b>Scheduling</b>\n        <ul>\n          <li>\n            Task of selecting a process from ready queue and allocating it to\n            CPU\n          </li>\n          <li>Records in the queue are generally the PCBs</li>\n          <li>CPU is allocated to the selected process by dispatcher</li>\n        </ul>\n        <b>Process</b>\n        <ul>\n          <li>CPU bound</li>\n          <li>IO bound</li>\n        </ul>\n        <b>Job scheduling : </b>which job to bring into memory\n        <br />\n        <b>CPU scheduling : </b>which job to run if several jobs are ready\n        <br />\n        <br />\n        <p>Process execution = CPU burst + I/O burst</p>\n        <b>Scheduling</b>\n        <ul>\n          <li>Non preemptive / cooperative</li>\n          <li>Preemptive</li>\n        </ul>\n        <p>\n          Dispatcher is the module that gives of the CPU to the process selected\n          by the short-term scheduler\n        </p>\n        <b>Dispatcher functions</b>\n        <ul>\n          <li>Switching context</li>\n          <li>Switching user mode</li>\n          <li>\n            Jumping to proper location in the user program to restart that\n            program\n          </li>\n        </ul>\n        Dispatcher should be extremely fast because it called every time a\n        context switch occurs\n        <br />\n        <b>Dispatch latency :</b> time it take for dispatcher to stop one\n        process and start another\n        <hr />\n        <h4>Scheduling criteria</h4>\n        <ul>\n          <li>CPU utilization</li>\n          <li>Throughput</li>\n          <li>Turn around time</li>\n          <li>Waiting time</li>\n          <li>Response time</li>\n        </ul>\n        <b>Measurements</b>\n        <ul>\n          <li>\n            <b>Burst time (BT):</b> time the process requires for running on\n            CPU.\n          </li>\n          <li>\n            <b>Waiting time (WT):</b> time spent by a process in ready state\n            waiting for CPU.\n          </li>\n          <li>\n            <b>Arrival time (AT):</b> time at which process arrives in ready\n            state.\n          </li>\n          <li>\n            <b>Exit time (ET):</b> when process completed its execution and\n            exits the system.\n          </li>\n          <li>\n            <b>Turn around time (TAT):</b> total time taken by a process in CPU\n            (process submission to completion).\n          </li>\n          <li>\n            <b>Response time :</b> time between a process enters the ready queue\n            and get scheduled on the CPU for the first time.\n          </li>\n        </ul>\n        <p>TAT = ET - AT = WT + BT</p>\n        <b>CPU scheduling evaluation criteria</b>\n        <ul>\n          <li>Average waiting time</li>\n          <li>Average response time</li>\n          <li>CPU utilization</li>\n        </ul>\n        <hr />\n        <h4>Algorithms</h4>\n        <ol>\n          <li>\n            <b>FCFS (non-preemptive)</b>\n            <ul>\n              <li>Low throughput</li>\n              <li>\n                <b>Convoy effect :</b> smaller process have to wait for long\n                time for bigger process to release CPU\n              </li>\n              <li>\n                <b>Advantage :</b> simple and easy to use/understand. must be\n                used for background process where execution is not urgent\n              </li>\n              <li>\n                <b>Disadvantage :</b> convoy effect, normally higher average\n                waiting time, no consideration of priority or burst time.\n              </li>\n              <li>Should not be used for interactive system</li>\n              <li>No starvation here, as processor is unbiased</li>\n            </ul>\n          </li>\n          <li>\n            <b>SJF</b>\n            <ul>\n              <li>Both preemptive SRTF and non-preemptive SJF</li>\n              <li>\n                SRTF is optimal as it guarantees minimum average waiting time\n              </li>\n              <li>Better average response time than FCFS</li>\n              <li>\n                Cannot be implemented as we dont know burst time of a process\n              </li>\n              <li>\n                Starvation of larger burst time process and higher response time\n                (Highest response ratio next - modification of SJF to solve\n                this)\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>Priority Scheduling</b>\n            <ul>\n              <li>Both preemptive and non-preemptive</li>\n              <li>\n                How priority defined:\n                <ul>\n                  <li>\n                    <b>Internally defined : </b>\n                    use some measurable quantity to compute the priority. Eg.\n                    time limits, memory requirements, no. of open files.\n                  </li>\n                  <li>\n                    <b>Externally defined : </b>set by criteria that are\n                    external to the OS. Eg. by user.\n                  </li>\n                </ul>\n              </li>\n              <li>\n                Problem of starvation : low priority process never get access of\n                CPU\n              </li>\n              <li>\n                Solution: Aging - increasing the priority of the process that\n                waits in the system for longer time\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>Round Robin</b>\n            <ul>\n              <li>Designed specially for time sharing systems</li>\n              <li>Like FCFS with preemption</li>\n              <li>Time quantum/time slice (generally 10 - 100ms)</li>\n              <li>Ready queue is treated as a circular queue</li>\n              <li>\n                In RR we need to keep in mind the time for context switching\n              </li>\n              <li>If time quantum is large then it will be like FCFS</li>\n              <li>\n                If time quantum is very small (compared to context switch time)\n                then overhead\n              </li>\n              <li>\n                Time quantum must be large with respect to context switch time\n              </li>\n              <li>Has higher TAT compared to SJF but better response</li>\n            </ul>\n          </li>\n          <li>\n            <b>Multilevel Queue Scheduling</b>\n            <ul>\n              <li>Ready queue is partitioned into several separate queues</li>\n              <li>\n                Processes are permanently assigned to one queue based on size,\n                priority or process type.\n              </li>\n              <li>Each queue has its own scheduling</li>\n              <li>\n                There must be scheduling among queues also i.e each queue gets a\n                certain amount of CPU time and within that time it executes its\n                processes.\n              </li>\n              <li>\n                Scheduling between queues are mostly implemented as fixed\n                priority preemptive scheduling (in fixed priority scheduling it\n                will first cater to the foreground process and then serve\n                background process).\n              </li>\n              <li>Starvation possible</li>\n            </ul>\n          </li>\n          <li>\n            <b>Multilevel Feedback Queue</b>\n            <ul>\n              <li>Processes may move between queues</li>\n              <li>\n                Processes with different CPU-burst characteristics are now\n                seperated\n              </li>\n              <li>\n                If process uses too much CPU time it is pushed to lower priority\n                queue\n              </li>\n              <li>\n                If process waits too long in lower priority queue, it is moved\n                to higher priority queue (aging prevents starvation)\n              </li>\n            </ul>\n          </li>\n        </ol>\n        <hr />\n        <h4>Thread Scheduling</h4>\n        <ul>\n          <li>OS schedules the kernel level threads</li>\n          <ul>\n            <li>\n              <b>Local scheduling :</b> thread library decides which thread to\n              put onto an available light weight process.\n            </li>\n            <li>\n              <b>Global scheduling :</b> kernel decides which kernel thread to\n              run exist.\n            </li>\n          </ul>\n        </ul>\n        <b>Contention scope</b>\n        <ol>\n          <li>\n            <b>Process contention scope : </b>On systems with many to many or\n            many to one models, the thread library schedules user level threads\n            to run on available light weight processes\n          </li>\n          <li>\n            <b>System contention scope : </b>Process of deciding which kernel\n            thread to run on CPU\n          </li>\n        </ol>\n        <b>Multiple processor scheduling (MPS)</b>\n        <ul>\n          <li>Multiple CPUs available, more complex</li>\n          <li>\n            Homogeneous processor : each process maintains its own private queue\n            of processes or threads\n          </li>\n          <li>Load balancing to improve performance may be done</li>\n          <li>Asymmetric multiprocessing (master-slave)</li>\n        </ul>\n        <b>Approaches to MPS</b>\n        <ul>\n          <li>\n            We assume processors are homogeneous and have UMA-uniform memory\n            access\n          </li>\n          <li>\n            Load sharing can occur with a common ready queue\n            <ul>\n              <li>\n                Each processor is self scheduling and selects a process from the\n                common queue\n              </li>\n              <li>One processor is appointed as scheduler (master-slave)</li>\n            </ul>\n          </li>\n          <li>\n            Asymmetric multiprocessing is easier than SMP because only one\n            machine can access the data\n          </li>\n          <li>But bottleneck may happen as only one is scheduling</li>\n          <li>Nowaday symmetric is more used</li>\n        </ul>\n        <b>Processor affinity :</b> migration of a process to another processor\n        is avoided because of the cost of invalidating the process and\n        repopulating the processor cache.\n        <ul>\n          <li>\n            <b>Soft affinity :</b> here OS tries to keep a process on one\n            processor, but cannot guarantee that it will happen.\n          </li>\n          <li>\n            <b>Hard affinity :</b> when OS can make a process not to migrate to\n            other processors.\n          </li>\n        </ul>\n        <b>Load balancing : </b>attempts to keep load evenly distributed across\n        all processors in SMP system.\n        <br />\n        Migration approaches\n        <ul>\n          <li>\n            <b>Push migration :</b>\n            load on each processors are checked and then distributed evenly in\n            case of any imbalance\n          </li>\n          <li>\n            <b>Pull migration : </b> an idle processor pulls a waiting task from\n            a busy processor\n          </li>\n        </ul>\n        <p>Multicore processors have very complicated scheduling issue</p>\n      </div>\n    ),\n  },\n  {\n    id: 2,\n    title: \"System Calls\",\n    content: (\n      <div>\n        <h1>System Calls</h1>\n        <hr />\n        <ul>\n          <li>Provides an interface to the services provided by the OS</li>\n          <li>\n            Application programmer uses API, the API makes system calls on\n            behalf of programmer\n          </li>\n          <li>\n            When a call is made, the user mode is switched to kernel mode, then\n            the address of the implementation of that called function is fetched\n            from a look up table and is executed\n          </li>\n          <li>\n            Methods to pass parameters:\n            <ol>\n              <li>Using registers</li>\n              <li>\n                Via registers storing address to a block or table in memory\n                holding parameters\n              </li>\n              <li>Via stack (parameters are pushed and popped)</li>\n            </ol>\n          </li>\n        </ul>\n        <hr />\n        <h4>Types of system calls</h4>\n        <ol>\n          <li>\n            <b>Process control</b>\n            <ul>\n              <li>Program may end normally or abort abnormally</li>\n              <li>\n                Program needs to loaded into main memory and transferred back\n                once the job is done\n              </li>\n              <li>Creating or terminating processes</li>\n              <li>\n                Wait for other process to release resource, signal waiting\n                processes that resource is now free\n              </li>\n              <li>Set or get process attributes</li>\n              <li>Allocate or free memory</li>\n              <li>\n                For above tasks related to processes, system calls are required\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>File manipulation</b>\n            <ul>\n              <li>create, delete, open, close, update files</li>\n              <li>\n                For above tasks related to files, system calls are required\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>Device manipulation</b>\n            <ul>\n              <li>Giving access to resource</li>\n              <li>Handling concurrent access to a resource</li>\n              <li>Deallocating resources once the work is done</li>\n              <li>Request, release, attach, detach device</li>\n              <li>get, set device attribute</li>\n              <li>\n                For above tasks related to devices, system calls are required\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>Information maintenance</b>\n            <ul>\n              <li>Transfer info from user program to OS</li>\n              <li>get, set time,date,file,process,device attributes</li>\n              <li>\n                For above tasks related to information, system calls are\n                required\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>Communication</b>\n            <ul>\n              <li>\n                2 models for inter process communication\n                <ol>\n                  <li>\n                    Message passing\n                    <ul>\n                      <li>Useful when small amount of data</li>\n                      <li>Easier to implement</li>\n                    </ul>\n                  </li>\n                  <li>\n                    Shared memory\n                    <ul>\n                      <li>Great speed</li>\n                      <li>\n                        Protection and synchronization problem for shared area\n                        access\n                      </li>\n                    </ul>\n                  </li>\n                </ol>\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>Protection</b>\n            <ul>\n              <li>Mechanism for controlling resources</li>\n              <li>Specially when connected over a network</li>\n            </ul>\n          </li>\n        </ol>\n        <hr />\n        <h4>Dual mode operation</h4>\n        <ul>\n          <li>User mode & kernel/monitor mode</li>\n          <li>Mode bit 0 : task executed on behalf of OS</li>\n          <li>Mode bit 1 : task executed on behalf of user</li>\n          <li>\n            Dual mode protects errant access to privileged locations which may\n            harm the systems integrity.\n          </li>\n          <li>Privileged instruction can only be executed in monitor mode.</li>\n        </ul>\n      </div>\n    ),\n  },\n  {\n    id: 3,\n    title: \"Designing OS\",\n    content: (\n      <div>\n        <h1>Designing OS</h1>\n        <hr />\n        <ul>\n          <li>No ideal solution exists</li>\n          <li>\n            Depends on requirements (like real time, large scale, scientific)\n          </li>\n          <li>User goals : fast,reliable, easy to use</li>\n          <li>\n            System goal : easy to design,maintain and implement, error free\n          </li>\n          <li>\n            Design goals: convenience, reliable, fast, flexible and efficient\n          </li>\n        </ul>\n        <p>\n          <b>Policy : </b>determines what is to be done\n          <br />\n          <b>Mechanism : </b>determines how it is to be done\n        </p>\n        <p>\n          Earlier OS was mostly implemented in machine language (adv. less\n          storage and fast OS). But now we use high level languages like C/C++\n          (adv. fast to develop but slow OS and inc. storage)\n        </p>\n        <hr />\n        <h4>Structures of design</h4>\n        <ol>\n          <li>\n            <b>Simple</b>\n            <ul>\n              <li>MS-DOS, UNIX initially</li>\n            </ul>\n          </li>\n          <li>\n            <b>Layered (modularity)</b>\n            <ul>\n              <li>n layers from hardware to the UI</li>\n            </ul>\n          </li>\n          <li>\n            <b>Microkernel</b>\n            <ul>\n              <li>\n                Unnecessary features are removed from kernel and made into\n                system and user programs\n              </li>\n              <li>Smaller kernel size</li>\n              <li>Ease of extending OS services by adding to user programs</li>\n            </ul>\n          </li>\n          <li>\n            <b>Modules</b>\n            <ul>\n              <li>Kernel modules implemented</li>\n              <li>OO approach</li>\n              <li>\n                Each core component is separate and talks with others using\n                interfaces\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>Virtual machine</b>\n            <ul>\n              <li>\n                VM is an isolated computing environment created by abstracting\n                resources from a physical machine.\n              </li>\n              <li>\n                Creates illusion of multiple processors but resources are\n                actually shared.\n              </li>\n              <li>\n                <b>Normal structure</b>\n                <table\n                  className=\"table table-sm table-bordered\"\n                  style={{ textAlign: \"center\", width: \"150px\" }}\n                >\n                  <tbody>\n                    <tr>\n                      <td>Processes</td>\n                    </tr>\n                    <tr>\n                      <td>Kernel</td>\n                    </tr>\n                    <tr>\n                      <td>Hardware</td>\n                    </tr>\n                  </tbody>\n                </table>\n              </li>\n              <li>\n                <b>VM structure</b>\n                <table\n                  className=\"table table-sm table-bordered\"\n                  style={{ textAlign: \"center\", width: \"260px\" }}\n                >\n                  <tbody>\n                    <tr>\n                      <td>Processes</td>\n                      <td>Processes</td>\n                      <td>Processes</td>\n                    </tr>\n                    <tr>\n                      <td>Kernel</td>\n                      <td>Kernel</td>\n                      <td>Kernel</td>\n                    </tr>\n                    <tr>\n                      <td>VM 1</td>\n                      <td>VM 2</td>\n                      <td>VM 3</td>\n                    </tr>\n                    <tr>\n                      <td colSpan=\"3\">VM implementation</td>\n                    </tr>\n                    <tr>\n                      <td>Hardware</td>\n                      <td>Hardware</td>\n                      <td>Hardware</td>\n                    </tr>\n                  </tbody>\n                </table>\n              </li>\n            </ul>\n          </li>\n        </ol>\n      </div>\n    ),\n  },\n  {\n    id: 4,\n    title: \"Process Management\",\n    content: (\n      <div>\n        <h1>Process Management</h1>\n        <hr />\n        <b>Program : </b>passive entity\n        <br />\n        <b>Process : </b>active entity\n        <br />\n        <br />\n        Single threaded process has one program counter.\n        <br />\n        Multi threaded process has one program counter per thread.\n        <br />\n        Processes run concurrently by multiplexing the CPU\n        <br />\n        <br />\n        <b>OS is responsible for :</b>\n        <ul>\n          <li>Process scheduling</li>\n          <li>Process creation and termination</li>\n          <li>Suspending and resuming</li>\n          <li>IPC</li>\n          <li>Process synchronization</li>\n          <li>Deadlock prevention</li>\n        </ul>\n        Process is the unit of work in most systems\n        <br />\n        <br />\n        <b>Threads</b>\n        <ul>\n          <li>They are lightweight processes</li>\n          <li>\n            Each thread of a process has its own resources but they share some\n            resources also.\n          </li>\n        </ul>\n        A process include\n        <ul>\n          <li>Program counter</li>\n          <li>Stack</li>\n          <li>Data section</li>\n        </ul>\n        <b>Process states</b>\n        <ul>\n          <li>New</li>\n          <li>Running</li>\n          <li>Waiting</li>\n          <li>Ready</li>\n          <li>Terminated</li>\n        </ul>\n        Scheduler Dispatch moves process from ready to running state\n        <hr />\n        <h4>Process Control Block (PCB)</h4>\n        PCB contains Information about\n        <ul>\n          <li>Process state</li>\n          <li>Program counter</li>\n          <li>CPU registers</li>\n        </ul>\n        <table\n          className=\"table table-sm table-bordered\"\n          style={{ textAlign: \"center\", width: \"150px\" }}\n        >\n          <tbody>\n            <tr>\n              <td>Process State</td>\n            </tr>\n            <tr>\n              <td>Process Number</td>\n            </tr>\n            <tr>\n              <td>Program Counter</td>\n            </tr>\n            <tr>\n              <td>Register</td>\n            </tr>\n            <tr>\n              <td>Memory limits</td>\n            </tr>\n            <tr>\n              <td>List of open files</td>\n            </tr>\n            <tr>\n              <td>etc ...</td>\n            </tr>\n          </tbody>\n        </table>\n        A process migrated between various queues\n        <br />\n        <br />\n        <b>Scheduling queues</b>\n        <ul>\n          <li>\n            <b>Job queue :</b> as process enters a system they are put here\n            <b>Ready queue :</b> processes in memory waiting for execution A\n            ready queue header contains pointers to the first and last PCBs in\n            the list, each PCBs of the list has a pointer to the next PCB\n            <b>Device queue :</b> List of processes waiting for an I/O device\n          </li>\n        </ul>\n        A process in execution can make\n        <ul>\n          <li>I/O request and would be out into the device queue</li>\n          <li>A sub-process and wait for its termination</li>\n          <li>Interrupted and go back to the ready queue</li>\n        </ul>\n        <b>Scheduler</b>\n        <ul>\n          <li>\n            <b>Long term scheduler / Job scheduler</b>\n            <ul>\n              <li>\n                Selects processes from pool (disk, secondary memory) and brings\n                it into the main memory for execution\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>Short term scheduler / CPU scheduler</b>\n            <ul>\n              <li>\n                Selects a process among set of ready to execute processes and\n                allocate CPU to it The main difference is in frequency of\n                execution. (short-term = more frequent)\n              </li>\n            </ul>\n          </li>\n        </ul>\n        Degree of multiprogramming (number of processes in main memory) It is\n        controlled by long term scheduler\n        <br />\n        <br />\n        <b>I/O bound processes :</b> spends more time on I/O\n        <br />\n        <b>CPU bound processes :</b> spends more time on doing computation\n        <br />\n        Long term scheduler should select processes having good mix of these two\n        <br />\n        <br />\n        <b>Context switch</b>\n        <ul>\n          <li>\n            Saving the state of the old process and switching to another process\n          </li>\n          <li>Context of process is represented by its PCB</li>\n        </ul>\n        <b>UNIX</b>\n        <ul>\n          <li>\n            <b>fork :</b> system call creates a new process\n            <b>exec :</b> system call used after a fork to replace the process'\n            memory space with a new program\n          </li>\n        </ul>\n        Independent process (unaffected by others) vs Cooperative process\n        (affected by others)\n        <hr />\n        <h4>Inter Process Communication (IPC)</h4>\n        <b>Message passing</b>\n        <ul>\n          <li>\n            ProcA -{\">\"} Kernel -{\">\"} ProcB\n          </li>\n          <li>Passing msgs without having a shared data</li>\n          <li>Messages can be fixed or variable size</li>\n          <li>Send() and receive() primitives should be provided</li>\n          <li>Communication link should be established</li>\n          <b>Direct</b>\n          <ul>\n            <li>sender -{\">\"} receiver</li>\n            <li>Sender should explicitly mention receiver's address</li>\n            <li>A link exist between each pair</li>\n          </ul>\n          <b>Indirect</b>\n          <ul>\n            <li>\n              sender -{\">\"} mailbox (ports) -{\">\"} receiver\n            </li>\n            <li>Multiple links can be present</li>\n          </ul>\n          <br />\n          <b>Symmetric</b>\n          <ul>\n            <li>\n              Both sender and receiver should name the other to communicate\n            </li>\n          </ul>\n          <b>Asymmetric</b>\n          <ul>\n            <li>Only sender needs to name the receiver to communicate</li>\n          </ul>\n          <br />\n          <b>Mailbox owned by a process</b>\n          <ul>\n            <li>The owner of the mailbox can only receive</li>\n            <li>Mailbox disappears when process terminates</li>\n          </ul>\n          <b>Mailbox owned by OS</b>\n          <ul>\n            <li>Can use the mailbox for both sending and receiving</li>\n            <li>\n              OS allows processes to create, delete, send and receive messages\n              via mailbox\n            </li>\n          </ul>\n          <b>Synchronization</b>\n          <ul>\n            <li>\n              <b>Blocking (sync.)</b>\n              <ul>\n                <li>Blocking send : sender blocked until msg is received</li>\n                <li>\n                  Blocking receive : receiver blocked until msg is available\n                </li>\n              </ul>\n            </li>\n            <li>\n              <b>Non-blocking (async.)</b>\n              <ul>\n                <li>Non-blocking send : sender sends and continue</li>\n                <li>\n                  Non-blocking receive : receiver receives valid msg or null\n                </li>\n              </ul>\n            </li>\n          </ul>\n          Rendezvous = when both send and receive are blocking\n          <br />\n          <br />\n          <b>Buffering : </b>messages exchanged reside on a temporary queue.\n          <ul>\n            <li>\n              zero capacity : link cant have any msg waiting in it sender\n              blocked until receiver receives\n            </li>\n            <li>\n              bounded capacity : sender blocked if full, otherwise keep on\n              sending\n            </li>\n            <li>\n              unbounded capacity : any no. of msgs can wait in queue, sender\n              never blocked\n            </li>\n          </ul>\n        </ul>\n        <b>Shared memory</b>\n        <ul>\n          <li>\n            ProcA -{\">\"} shared memory -{\">\"} ProcB\n          </li>\n          <li>Have a common buffer pool</li>\n          <li>\n            Eg. Producer consumer problem (unbounded buffer, bounded buffer)\n          </li>\n        </ul>\n        <b>Communication in client server system</b>\n        <ol>\n          <li>\n            <b>Socket</b>\n            <ul>\n              <li>Socket is an endpoint of communication</li>\n              <li>Sockets are identified by IP address + port number</li>\n              <li>\n                Sever implement specific services (telnet, ftp, http) and\n                listens to well known ports below 1024\n              </li>\n              <li>\n                Client is assigned a port number by the host computer {\">\"} 1024\n              </li>\n              <li>Sockets are considered low level</li>\n              <li>RPC and RMI are higher level</li>\n            </ul>\n          </li>\n          <li>\n            <b>RPC</b>\n            <ul>\n              <li>\n                Msgs are well structured, contains id of function to be executed\n                and its parameters\n              </li>\n              <li>\n                RPC daemon(process that always runs in the background) listens\n                to a port on remote system\n              </li>\n              <li>Msgs are addressed to RPC daemon</li>\n              <li>\n                Function is executed and reply is sent back in another message\n              </li>\n              <li>\n                RPC provides stub (client side proxy for actual procedure to\n                hide the details of communication)\n              </li>\n              <li>\n                Stub locates the correct port on the server and marshalls the\n                parameters in the correct format for transmission over network\n              </li>\n              <li>\n                Similar stub on server side which unpacks the msg and invokes\n                the procedure and returns values\n              </li>\n              <li>\n                RPC can represent data in machine independent way using XDR\n                (External Data Representation) Marshalling converts data from\n                machine dependent to XDR and vice-versa\n              </li>\n              <li>\n                <b>Binding client and server</b>\n                <ul>\n                  <li>\n                    The port numbers can be fixed and therefore predetermined\n                  </li>\n                  <li>\n                    Binding can also be done dynamically by matchmaker daemon\n                  </li>\n                </ul>\n              </li>\n              <li>\n                <b>Steps</b>\n                <ol>\n                  <li>User calls kernel to send RPC msg</li>\n                  <li>Kernel contacts matchmaker to find port number</li>\n                  <li>Matchmaker replies to client with port number</li>\n                  <li>Kernel sends RPC to the correct port</li>\n                  <li>\n                    Daemon listening to port for requests and then calls\n                    specific procedure and return result\n                  </li>\n                  <li>Kernel receives it and sends back to user</li>\n                </ol>\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>RMI</b>\n          </li>\n        </ol>\n        <b>Pipes : </b>it allows two processes to communicate.\n        <ul>\n          <li>\n            <b>Ordinary pipe (named anonymous pipes on windows)</b>\n            <ul>\n              <li>\n                Allows communication only between parent and child process\n              </li>\n              <li>They are unidirectional</li>\n              <li>\n                Eg producer-consumer : producer writes to pipe, consumer reads\n                from the pipe\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>Named pipe</b>\n            <ul>\n              <li>More powerful than ordinary pipes</li>\n              <li>Allows communication between unrelated processes</li>\n              <li>Bidirectional / no parent-child relationship</li>\n            </ul>\n          </li>\n        </ul>\n        <hr />\n        <h4>Multi threaded programming</h4>\n        <b>Thread :</b> fundamental unit of CPU utilization in multi-threaded\n        programming\n        <ul>\n          <li>It is flow of control within a process</li>\n          <li>\n            Multi-threaded process contains several different flows of control\n            within the same address space\n          </li>\n          <li>Lightweight process</li>\n          <li>\n            A thread has its own ID, program counter, register set and stack\n          </li>\n          <li>\n            It shares code section, data section and other OS resources with\n            threads of the same process\n          </li>\n          <li>\n            If a process has multiple threads the it can perform more than one\n            task at a time\n          </li>\n          <li>\n            Each thread runs on separate CPU, increasing concurrency and\n            parallelism\n          </li>\n        </ul>\n        <table\n          className=\"table table-sm table-bordered\"\n          style={{ textAlign: \"center\", width: \"150px\" }}\n        >\n          <tbody>\n            <tr>\n              <td>T1</td>\n              <td>T2</td>\n              <td>T3</td>\n            </tr>\n            <tr>\n              <td>Registers</td>\n              <td>Registers</td>\n              <td>Registers</td>\n            </tr>\n            <tr>\n              <td>Stack</td>\n              <td>Stack</td>\n              <td>Stack</td>\n            </tr>\n            <tr>\n              <td colSpan=\"3\">code & data & files</td>\n            </tr>\n          </tbody>\n        </table>\n        <b>2 types of threads</b>\n        <ol>\n          <li>\n            <b>User level threads</b>\n            <ul>\n              <li>Visible to a programmer but not to kernel</li>\n              <li>Implemented by thread library/API</li>\n              <li>Faster to create and manage as kernel doesn;t intervene</li>\n              <li>\n                Disadv: if the kernel is single threaded then any user level\n                thread performing a blocking system call will block the entire\n                process\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>Kernel level threads</b>\n            <ul>\n              <li>OS kernel supports and manages it</li>\n              <li>Slower to create and manage</li>\n              <li>\n                If kernel thread performs a blocking system call then it can\n                schedule another thread on different core/processor\n              </li>\n            </ul>\n          </li>\n        </ol>\n        <p>\n          Multi threading is more efficient than multi processes\n          <br />\n          RPC generally multi-threaded\n          <br />\n          Whenever a new request comes it creates a new thread to serve it and\n          again listens for other requests\n        </p>\n        <b>Benefits of Multi-threading</b>\n        <ul>\n          <li>Responsiveness</li>\n          <li>Resource sharing</li>\n          <li>Economy (resource sharing among processes is costly)</li>\n          <li>Scalability</li>\n        </ul>\n        <b>Thread models</b>\n        <ul>\n          <li>\n            <b>Many to one</b>\n            <ul>\n              <li>Many user level threads mapped to one kernel thread</li>\n              <li>Thread management is done in user space so efficient</li>\n              <li>Entire process blocks if thread makes a blocking call</li>\n              <li>Multiple threads can't run in parallel on multiprocessors</li>\n            </ul>\n          </li>\n          <li>\n            <b>One to one</b>\n            <ul>\n              <li>Each user thread is mapped to one kernel thread</li>\n              <li>\n                More concurrency as other threads can run even if one thread\n                makes a blocking call\n              </li>\n              <li>Threads can run in parallel on multiple processors</li>\n              <li>\n                Each new user level thread needs a corresponding kernel level\n                thread (overhead, performance loss)\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>Many to many</b>\n            <ul>\n              <li>\n                Many user level threads are multiplexed to a smaller/equal\n                number of threads\n              </li>\n              <li>Can run in parallel</li>\n              <li>\n                Then a thread performs a blocking call, the kernel can schedule\n                another thread for execution\n              </li>\n            </ul>\n          </li>\n        </ul>\n        <b>Thread Cancellation :</b> task of terminating a thread(target thread)\n        <ul>\n          <li>\n            <b>Asynchronous cancellation</b>\n            <ul>\n              <li>One thread terminates target thread</li>\n              <li>Target thread may not free the acquired resources</li>\n            </ul>\n          </li>\n          <li>\n            <b>Deferred cancellation</b>\n            <ul>\n              <li>\n                Target thread can periodically check if it should terminate\n              </li>\n            </ul>\n          </li>\n        </ul>\n        <b>Signal handling : </b> notifying a process/thread that some event has\n        occurred\n        <ul>\n          <li>\n            <b>Synchronous signal</b>\n            <ul>\n              <li>\n                Signal sent to same process/thread that caused signal generation\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>Asynchronous signal</b>\n            <ul>\n              <li>\n                Signal generated by an event external to a running process\n              </li>\n            </ul>\n          </li>\n          Every signal must be handled\n          <ul>\n            <li>User defined signal handler</li>\n            <li>Default signal handler (run by kernel)</li>\n          </ul>\n        </ul>\n        <b>Thread pools</b>\n        <ul>\n          <li>\n            Create a number of threads at startup and place them in a pool where\n            they wait for work\n          </li>\n          <li>\n            When server receives a request it awakens a thread and assigns work\n            to it\n          </li>\n          <li>On completion thread returns back to the pool</li>\n          <li>\n            Benefits:\n            <ul>\n              <li>\n                Faster to respond to a request as no need of new thread creation\n              </li>\n              <li>\n                Thread pool limits the number of threads that can exist...no\n                infinite growth\n              </li>\n            </ul>\n          </li>\n        </ul>\n        <b>Scheduler activation</b>\n        <ul>\n          <li>\n            There needs to be communication between user and kernel level\n            threads so that appropriate number of kernel level threads are\n            allocated to the application.\n          </li>\n          <li>\n            Scheduler activation provides upcalls - a communication mechanism\n            from kernel to thread library.\n          </li>\n          <li>\n            Required to maintain the correct number of kernel level threads.\n          </li>\n        </ul>\n      </div>\n    ),\n  },\n  {\n    id: 5,\n    title: \"Process Synchronization\",\n    content: (\n      <div>\n        <h1>Process Synchronization</h1>\n        <hr />\n        <b>Cooperating process</b>\n        <ul>\n          <li>One that can affect or can be affected by other processes.</li>\n          <li>\n            They may share logical address space (i.e. code and data), or share\n            data through files or messages through threads.\n          </li>\n          <li>\n            Concurrent access to shared data can result in inconsistencies.\n          </li>\n          <li>\n            There has to be orderly execution of cooperating processes to ensure\n            consistency.\n          </li>\n        </ul>\n        <b>Race condition : </b>when the outcome of the execution depends on the\n        order in which data access takes place.\n        <br />\n        <br />\n        <b>Critical section</b>\n        <ul>\n          <li>\n            A segment of code in which a process maybe changing common\n            variables, updating a table or writing a file etc.\n          </li>\n          <li>A section where we access the shared resource.</li>\n          <li>\n            Entry section : Request permission to enter the critical section\n          </li>\n          <li>\n            Critical section : Mutually exclusive in time (no other process can\n            execute in its critical section)\n          </li>\n          <li>Exit section : Follows the critical section</li>\n          <li>Remainder section</li>\n        </ul>\n        <b>Solution to critical section problem must satisfy :</b>\n        <ol>\n          <li>\n            <b>Mutual exclusion :</b> (mandatory)\n            <ul>\n              <li>Only one process can be in critical section.</li>\n            </ul>\n          </li>\n          <li>\n            <b>Progress :</b> (mandatory)\n            <ul>\n              <li>\n                Only those processes which are not in the remainder section can\n                enter the critical section and the selection of the process\n                cannot be postponed indefinitely\n              </li>\n              <li>\n                Only those processes interested in entering into the critical\n                section should compete for it.\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>Bounded waiting : </b>(optional)\n            <ul>\n              <li>\n                There must be a bound on the number of times other processes are\n                allowed to enter into the critical section after a process has\n                made a request to enter in the critical section and before the\n                request is granted.\n              </li>\n            </ul>\n          </li>\n        </ol>\n        <b>Software solution</b>\n        <ul>\n          <li>\n            <b>Using 2 turn variables</b>\n            <ul>\n              <li>Satisfies mutual exclusion</li>\n              <li>\n                Does NOT satisfy progress hence faulty (because of strict\n                aternations even if process doesn't want to enter CS)\n              </li>\n            </ul>\n          </li>\n\n          <li>\n            <b>Using flag variable - flag[2]</b>\n            <ul>\n              <li>Satisfies mutual exclusion</li>\n              <li>\n                Satisfies progress (no strict alternation and interest of a\n                process is considered)\n              </li>\n              <li>\n                But deadlock possible if context switch happens in entry section\n                and flag become [T,T]\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>Peterson's solution</b>\n            <ul>\n              <li>Uses both flag and turn variable</li>\n              <li>\n                Satisfies all 3 conditions (mutual exclusion, progress and\n                bounded wait)\n              </li>\n              <li>\n                Difficult to scale up to n-processes (solution is semaphores)\n              </li>\n            </ul>\n          </li>\n        </ul>\n        <b>Peterson's solution</b>\n        <ul>\n          <li>Software solution that can be used to prevent race condition</li>\n          <li>Two process solution</li>\n          <li>\n            Assumes that LOAD and STORE instructions are atomic and cannot be\n            interrupted\n          </li>\n          <li>\n            The 2 processes share two variables\n            <ol>\n              <li>\n                int turn\n                <ul>\n                  <li>\n                    Turn indicates whose turn it is to enter the critical\n                    section\n                  </li>\n                </ul>\n              </li>\n              <li>\n                boolean flag[2]\n                <ul>\n                  <li>\n                    Flag array is used to indicate if a process is ready to\n                    enter into the critical section\n                  </li>\n                  <li>\n                    flag[i]=true implies process P<sub>i</sub> is ready\n                  </li>\n                </ul>\n              </li>\n            </ol>\n          </li>\n        </ul>\n        <b>Hardware solutions</b>\n        <ul>\n          <li>\n            <b>Locks</b>\n            <ul>\n              <li>Acquiring and releasing locks</li>\n              <li>\n                Atomic instruction running on different CPUs will run\n                sequentially\n              </li>\n              <li>\n                <b>Semaphores</b>\n                <ul>\n                  <li>\n                    A synchronization tool used to control access to shared\n                    variables so that only one process at any point of time\n                    change the value of the shared variable.\n                  </li>\n                  <li>\n                    A semaphore S is an integer variable that is accessed only\n                    through two standard atomic operations wait and signal.\n                    <br />\n                    <br />\n                    wait(s){\" {\"}\n                    <br />\n                    while(s{\"<\"}=0);\n                    <br /> s--;\n                    <br />\n                    {\"}\"}\n                    <br />\n                    <br />\n                    signal(s){\" {\"}\n                    <br />\n                    s++;\n                    <br />\n                    {\"}\"}\n                  </li>\n                  Two types\n                  <ul>\n                    <li>\n                      <b>Counting :</b> allows n processes to access the shared\n                      resource by initializing semaphore to n n processes share\n                      the semaphore(aka mutex) initialised to 1.\n                    </li>\n                    <li>\n                      <b>Binary :</b> semaphore value only 0 or 1.\n                    </li>\n                  </ul>\n                  <b>Mutual exclusion solution</b>\n                  <p>\n                    do{\" {\"}\n                    <br />\n                    wait(mutex);\n                    <br />\n                    critical section\n                    <br />\n                    signal(mutex);\n                    <br />\n                    {\"}\"} while(true);\n                  </p>\n                  <b>Disadvantage</b>\n                  <ul>\n                    <li>\n                      They all require busy waiting (process trying to enter\n                      critical section must loop continuously in the entry code)\n                    </li>\n                    <li>This wastes CPU cycle</li>\n                    <li>\n                      This type of semaphore is also called spinlock(because\n                      process spins while waiting for lock)\n                    </li>\n                  </ul>\n                  <b>Advantage</b>\n                  <ul>\n                    <li>\n                      No context switch is required when a process waits for a\n                      lock (useful for short period)\n                    </li>\n                  </ul>\n                </ul>\n              </li>\n              <li>\n                Implementing a semaphore with waiting queue can cause deadlock\n                issue\n              </li>\n              <li>\n                <b>Deadlock : </b>caused when a process in the waiting set is\n                waiting for an event/resource held by another process in the\n                waiting set in circular manner\n              </li>\n              <li>\n                <b>Starvation : </b>when a process waits indefinitely within the\n                semaphore\n              </li>\n              <li>\n                <b>Priority Inversion : </b>when a high priority process needs\n                data currently being accessed by lower priority process\n              </li>\n            </ul>\n          </li>\n        </ul>\n        <b>Classic problems of synchronization</b>\n        <ol>\n          <li>\n            <b>Bounded buffer problem</b>\n            <ul>\n              <li>\n                There is a pool of n buffers each capable of holding one item\n              </li>\n              <li>\n                Empty and full semaphores count the number of empty and full\n                buffers\n              </li>\n              <li>\n                Mutex semaphore provide mutual exclusion for access to the\n                buffer pool\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>Readers-writers problem</b>\n            <ul>\n              <li>Data is shared among number of concurrent processes</li>\n              <li>Readers only read the data and do not update</li>\n              <li>Writers can both read and write</li>\n              <li>Many readers can access at the same time</li>\n              <li>Writers need exclusive use to shared objects</li>\n              <li>Both reader and writer starvation possible</li>\n            </ul>\n          </li>\n          <li>\n            <b>Dining-philosopher problem</b>\n            <ul>\n              <li>5 philosopher and 5 chopsticks</li>\n              <li>Philosopher wither eats or thinks</li>\n              <li>Semaphore chopstick[5];</li>\n              <li>\n                He acquires a chopstick by wait operation and releases it by\n                signal operation\n              </li>\n              <li>No two neighbours can eat together</li>\n              <li>Deadlock possible</li>\n              <li>\n                Sol: only pick if both are available or odd one will pick left\n                chopstick first and even one will pick right chopstick first\n              </li>\n              <li>Starvation still possible</li>\n            </ul>\n          </li>\n          Monitors is the solution for this problem\n        </ol>\n        <b>Monitors</b>\n        <ul>\n          <li>\n            It is a high level abstraction that provides a convenient and\n            effective mechanism for process synchronization\n          </li>\n          <li>Only one process may be active within a monitor at a time</li>\n          <li>\n            Monitors are needed because if all processes use semaphore and one\n            process accidentally forgets to signal then all will be deadlocked\n          </li>\n          <li>\n            Monitor is a collection of procedures, variables, and data\n            structures that are grouped together in a module/package\n          </li>\n        </ul>\n        <b>Atomicity : </b>either full operation takes place or none.\n        <br />\n        <b>Transaction :</b> set of operations which is successful ends with\n        commit or if failed ends with abort.\n        <br />\n        <b>Serializability :</b> when transactions are executed serially and\n        atomically.\n        <br />\n        <br />\n        Schedule - S1\n        <table\n          className=\"table table-sm table-bordered\"\n          style={{ textAlign: \"center\", width: \"150px\" }}\n        >\n          <tbody>\n            <tr>\n              <td>T1</td>\n              <td>T2</td>\n            </tr>\n            <tr>\n              <td>read()</td>\n              <td></td>\n            </tr>\n            <tr>\n              <td>write()</td>\n              <td></td>\n            </tr>\n            <tr>\n              <td></td>\n\n              <td>write()</td>\n            </tr>\n            <tr>\n              <td></td>\n              <td>read()</td>\n            </tr>\n          </tbody>\n        </table>\n        <p>\n          <b>Non-serial schedule:</b> transactions can overlap\n          <br />\n          Conflict if in two overlapping operations on same data item and one is\n          write() operation.\n        </p>\n        Schedule - S2\n        <table\n          className=\"table table-sm table-bordered\"\n          style={{ textAlign: \"center\", width: \"150px\" }}\n        >\n          <tbody>\n            <tr>\n              <td>T1</td>\n              <td>T2</td>\n            </tr>\n            <tr>\n              <td>read()</td>\n              <td></td>\n            </tr>\n            <tr>\n              <td>write(A)</td>\n              <td>read(A)</td>\n            </tr>\n            <tr>\n              <td>write(A)</td>\n              <td>read(B)</td>\n            </tr>\n            <tr>\n              <td></td>\n              <td>write()</td>\n            </tr>\n            <tr>\n              <td></td>\n              <td>read()</td>\n            </tr>\n          </tbody>\n        </table>\n        If O<sub>i</sub> and O<sub>j</sub> are consecutive operations of\n        different transactions (S) and do not conflict then their order can be\n        swapped (S') without any issue.\n        <br />\n        <br />S becomes S' via swapping non-conflicting operations and both are\n        equivalent then S is conflict serializable.\n        <br />\n        <br />\n        <b>Log based recovery</b>\n        <ul>\n          <li>\n            <b>Write ahead log</b>\n            <br />\n            each log records describe a single operation of a transaction write\n            and has these fields:\n            <ol>\n              <li>Transaction name</li>\n              <li>Data item name (data being written)</li>\n              <li>Old value</li>\n              <li>New value</li>\n            </ol>\n            <b>Disadvantage</b>\n            <ul>\n              <li>For each write operation a write on log is also required.</li>\n            </ul>\n            <b>Recovery procedure</b>\n            <ul>\n              <li>undo - restore old values</li>\n              <li>redo - set data to new values</li>\n            </ul>\n          </li>\n        </ul>\n        <b>Checkpoints</b>\n        <ul>\n          <li>\n            Maintain checkpoints so it is easier to roll back to last checkpoint\n            rather than going back each transaction, which is time consuming.\n          </li>\n        </ul>\n      </div>\n    ),\n  },\n  {\n    id: 6,\n    title: \"Deadlocks\",\n    content: (\n      <div>\n        <h1>Deadlocks</h1>\n        <hr />\n        <p>\n          A deadlocked state occurs when two or more process are waiting\n          indefinitely for an event that can be caused only by one of the\n          waiting processes.\n        </p>\n        <b>Necessary conditions</b> (deadlock situation can occur if all these\n        situation hold simultaneously)\n        <ol>\n          <li>\n            <b>Mutual exclusion</b>\n            <ul>\n              <li>\n                At least one resource should be held in non-sharable mode (i.e\n                can be used by only one at a time)\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>Hold and wait</b>\n            <ul>\n              <li>\n                A process must hold at least one resource and be waiting for\n                another resource held by another process\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>No pre-emption</b>\n            <ul>\n              <li>A resource can only be released voluntarily by a process</li>\n            </ul>\n          </li>\n          <li>\n            <b>Circular wait</b>\n            <ul>\n              <li>\n                In a set of waiting processes, all are waiting for a resource\n                held by another process in the set (in a circular fashion)\n              </li>\n            </ul>\n          </li>\n          All 4 conditions must hold for a deadlock to occur\n        </ol>\n        <b>Resource allocation graph</b>\n        <ul>\n          <li>\n            Vertices - Pi processes (bubble) and Rj resources (square with dots\n            denoting no. of instances)\n          </li>\n          <li>Request edge Pi-{\">\"}Rj</li>\n          <li>Assignment edge Ri-{\">\"}Pj</li>\n          <li>If it contains no cycle then no deadlock</li>\n          <li>\n            If it contains cycle then deadlock may or may not be in deadlock\n            <ul>\n              <li>If only one instance per resource type then deadlock</li>\n              <li>\n                If several instances per resource type then possibility of\n                deadlock\n              </li>\n            </ul>\n          </li>\n        </ul>\n        <b>3 ways of dealing with deadlock</b>\n        <ol>\n          <li>Use protocols to avoid or prevent deadlock</li>\n          <li>\n            Allow system to enter deadlock then state, detect it and recover\n          </li>\n          <li>Ignore the problem and pretend that it will never occur</li>\n        </ol>\n        <b>Deadlock handling methods</b>\n        <ul>\n          <li>Prevention</li>\n          <li>Avoidance</li>\n          <li>Detection and recovery</li>\n          <li>Ignorance / ostrich algo</li>\n        </ul>\n        <b>Good approaches</b>\n        <ul>\n          <li>\n            <b>Deadlock prevention : </b>make sure at least one of the 4\n            conditions cannot hold\n          </li>\n          <li>\n            <b>Deadlock avoidance : </b>information about processes and the\n            resources it requires will be given to OS in advance and OS will\n            make smart decisions\n          </li>\n        </ul>\n        <hr />\n        <h4>Deadlock prevention</h4>\n        <b>Mutual exclusion</b>\n        <ul>\n          <li>\n            Only for non-sharable resources and we cannot resolve mutual\n            exclusion in such case\n          </li>\n          <li>Sharable resources have no issue</li>\n        </ul>\n        <b>Hold and Wait</b>\n        <ul>\n          <li>\n            <b>Do not hold :</b> Process requesting a resource may not hold any\n            resource, before requesting something it would release all held\n            resources. efficient\n          </li>\n          <li>\n            <b>Conservative approach :</b> Process can only request resources at\n            the start of execution and not in the middle. So all resources\n            required should be allocated at the start itself. less efficient\n          </li>\n          <li>\n            <b>Wait timeout :</b> a process can wait only for a certain time\n            period. after which a process must release all resources\n            <ul>\n              <li>\n                Resource utilization will be low as it will remain unutilized\n                for long periods\n              </li>\n              <li>\n                Starvation possible, a process needing several resources may\n                have to wait long\n              </li>\n            </ul>\n          </li>\n        </ul>\n        <b>No preemption</b>\n        <ul>\n          <li>Forcefull preemption</li>\n          <li>\n            <b>Sol1:</b> if a process holds some resources and requests another\n            resource that can't be immediately allocated to it, then all\n            resources currently held by it are implicitly released. The process\n            is restarted only when all required resources are available.\n          </li>\n          <li>\n            <b>Sol2:</b> If requested resource is not available, then check its\n            status whether it is held by another process which is waiting. If\n            this is the case, preempt the resources and give it to the\n            requestor.\n          </li>\n        </ul>\n        <b>Circular wait</b>\n        <ul>\n          <li>\n            Impose ordering of all resource types and require that each process\n            request resources in increasing or decreasing order (any one).\n          </li>\n          <li>\n            Require that whenever a process requests an instance of resource\n            type, it has released resources with lower number.\n          </li>\n        </ul>\n        <b>Safe state</b>\n        <ul>\n          <li>\n            A state is safe if a system can allocate resources to each process\n            in some order and still avoid deadlock\n          </li>\n          <li>\n            Safe sequence : if requested resource is free or requested resource\n            by P<sub>i</sub> is held by process P<sub>j</sub> where j{\"<\"}i.\n            When lower process frees then the higher processes can continue\n          </li>\n        </ul>\n        <b>Resource allocation graph algorithm</b>\n        <ul>\n          <li>\n            Claim edge : dotted edge P<sub>i</sub>-{\">\"}R<sub>j</sub>{\" \"}\n            representing P<sub>i</sub> may request R<sub>j</sub>\n          </li>\n          <li>Request edge : when process requests a resource</li>\n          <li>Assignment edge : when a resource is allocated to a process</li>\n          <li>Resources must be claimed a priori in the system</li>\n          <li>\n            Request can only be granted if converting a request edge to\n            assignment edge does not result in the formation of a cycle in the\n            resource allocation graph.\n          </li>\n        </ul>\n        <b>Bankers algorithm (for deadlock avoidance)</b>\n        <ul>\n          <li>\n            First use bankers safety algorithm to check whether the system is in\n            safe state\n          </li>\n          <li>\n            Then use the resource request algorithm to check whether each of the\n            given requests may be safely granted or not.\n          </li>\n          <li>\n            Each process has\n            <ul>\n              <li>Allocation vector : no. of each resource type allocated</li>\n              <li>\n                Max vector : the maximum number of each resource to be used\n              </li>\n              <li>Need vector : outstanding resources (max - allocation)</li>\n            </ul>\n          </li>\n          <li>Available/work vector : free resources over all processes</li>\n          <li>\n            Maximum resource vector : allocation vectors + available vector\n          </li>\n          <li>Finish vector : indicates which processes are still running</li>\n          <li>\n            Disadvantages\n            <ul>\n              <li>It requires fixed number of resources to allocate</li>\n              <li>Resources may breakdown suddenly</li>\n              <li>Process rarely know their max resource needs in advance</li>\n              <li>\n                It requires a fixed number of processes but in real life it may\n                vary dynamically\n              </li>\n            </ul>\n          </li>\n        </ul>\n        <hr />\n        <h4>Deadlock detection</h4>\n        <ul>\n          <li>\n            Determines if deadlock has occurred. If occured the run recovery\n            algorithm\n          </li>\n          <li>\n            <b>Adv :</b> process needs not to be known in advance\n          </li>\n          <li>\n            <b>Disadv :</b> detection and recovery schemes require overhead and\n            some losses occur while recovering from deadlock\n          </li>\n        </ul>\n        If single instance of each resource type\n        <ul>\n          <li>\n            We maintain a wait-for graph\n            <ul>\n              <li>Nodes are processes</li>\n              <li>\n                P<sub>i</sub>-{\">\"}P<sub>j</sub> (P<sub>i</sub> is waiting for P\n                <sub>j</sub>)\n              </li>\n              <li>Cycle in wait-for graph represents deadlock</li>\n            </ul>\n          </li>\n        </ul>\n        If several instances of a resource type\n        <ul>\n          <li>Wait-for graph not applicable</li>\n          <li>\n            Here we use deadlock detection algorithm with specific data\n            structure\n            <ul>\n              <li>\n                Available : vector of length m indicating no. of resources of\n                each type\n              </li>\n              <li>\n                Allocation : an n x m matrix denoting no. of resources allocated\n                to each process\n              </li>\n              <li>\n                Request : an n x m matrix indicated the current request of each\n                process Request[i][j]=k -{\">\"} P<sub>i</sub> requests K\n                instances of resource R<sub>j</sub>\n              </li>\n            </ul>\n          </li>\n        </ul>\n        Issue is when to call and at what frequency to call the detection\n        algorithm Recovery from deadlock.\n        <br />\n        Once detected\n        <ul>\n          <li>System admin can terminate</li>\n          <li>Automatic termination</li>\n        </ul>\n        <b>Resource preemption</b>\n        <ul>\n          <li>Selecting victim (whom to abort)</li>\n          <li>Rollback (go back to safe state and start again)</li>\n          <li>\n            Starvation (same process is selected as victim for a long time, so\n            it must be picked a small no. of times)\n          </li>\n        </ul>\n      </div>\n    ),\n  },\n  {\n    id: 7,\n    title: \"Memory Management\",\n    content: (\n      <div>\n        <h1>Memory Management</h1>\n        <hr />\n        <ul>\n          <li>\n            Keeping track of which parts of memory are currently being used and\n            by whom\n          </li>\n          <li>\n            Deciding which processes are to be loaded into memory if space is\n            available\n          </li>\n          <li>Allocating and deallocating memory space as needed</li>\n          <li>\n            For any program to run, it must be mapped to absolute addresses and\n            loaded into memory\n          </li>\n          <li>CPU generates address for secondary memory (logical address)</li>\n        </ul>\n        <b>Basic hardware</b>\n        <ul>\n          <li>\n            Main memory and registers can only be accessed by CPU directly\n          </li>\n          <li>Register access takes only one CPU cycle</li>\n          <li>Main memory access take many cycles</li>\n          <li>Cache sits between main memory and registers</li>\n          <li>\n            Protection of memory required to be ensured for correct operation\n          </li>\n          <li>\n            A pair of Base and Limit registers define the logical(virtual)\n            address space\n          </li>\n          <li>\n            Base = 300040 (address at which a process' first block resides)\n            <br />\n            Suppose the process ends at address 420940 then,\n            <br /> Limit = 420940 - 300040 = 120900 (logical address space)\n          </li>\n        </ul>\n        <b>Address binding</b>\n        <ul>\n          <li>Binding of instructions and data to memory addresses</li>\n          <li>\n            Input queue : collection of processes in disk waiting to be loaded\n            into memory for execution\n          </li>\n          <li>Processes can reside in any parts of the memory</li>\n          <li>Addresses used in source program are symbolic</li>\n          <li>\n            Compiler binds these symbolic addresses to relocatable addresses\n          </li>\n          <li>\n            Linkage editor/loader binds these relocatable addresses to absolute\n            addresses\n          </li>\n        </ul>\n        <b>3 stages of address binding</b>\n        <ol>\n          <li>\n            <b>Compile time</b>\n            <ul>\n              <li>\n                If memory location known apriori, absolute code can be generated\n              </li>\n              <li>Recompilation required if memory location changes</li>\n            </ul>\n          </li>\n          <li>\n            <b>Load time</b>\n            <ul>\n              <li>Memory location is not known at compile time</li>\n              <li>It must generate relocatable addresses</li>\n            </ul>\n          </li>\n          <li>\n            <b>Execution time</b>\n            <ul>\n              <li>\n                Binding delayed until runtime, if processes can moved in memory\n                during execution\n              </li>\n              <li>Needs hardware support (base and limit registers)</li>\n            </ul>\n          </li>\n        </ol>\n        <p>\n          <b>Logical address :</b> generated by CPU.\n          <br />\n          <b>Physical address :</b> one seen by memory unit, and loaded into\n          memory address register of the memory.\n        </p>\n        <ul>\n          <li>\n            Compile time and load time address binding methods generate\n            identical logical and physical addresses.\n          </li>\n          <li>\n            Execution time address binding results in differing logical(virtual)\n            and physical address.\n          </li>\n        </ul>\n        <p>\n          <b>Logical address space :</b> the set of all logical addresses\n          generated by a program pointing to locations in secondary memory.\n          <br />\n          <b>Physical address space :</b> the set of all physical addresses\n          corresponding to these logical addresses. Physical address points to\n          location in main memory.\n        </p>\n        Logical address {\"<\"} Limit register value otherwise trap generated.\n        <hr />\n        <h4>MMU (memory management unit)</h4>\n        <ul>\n          <li>\n            A hardware device that does the run-time mapping from virtual to\n            physical addresses\n          </li>\n          <li>\n            The value in relocation(base) register is added to every address\n            generated by user process at the time it is sent to memory\n          </li>\n          <li>\n            User program never sees the physical address, it works with logical\n            address\n          </li>\n        </ul>\n        logical address + relocation register value = physical address\n        <br />\n        <br />\n        <b>Dynamic loading</b>\n        <ul>\n          <li>Routine is not loaded until it is called</li>\n          <li>\n            When executing program calls a routine, first it is checked if that\n            routine is already loaded in memory or not. If not the relocatable\n            linking loader is called to load the desired routine into memory\n          </li>\n          <li>Adv. : unused routine is never loaded</li>\n        </ul>\n        <b>Static linking</b>\n        <ul>\n          <li>\n            System language libraries are treated like any other object module\n            and are combined by the loader into the binary program image.\n          </li>\n        </ul>\n        <b>Dynamic linking</b>\n        <ul>\n          <li>Linking is postponed until execution</li>\n        </ul>\n        <b>Stub : </b>a stub is found in the image for each library routine\n        reference\n        <ul>\n          <li>It tells how to locate the library routine if already loaded</li>\n          <li>\n            It tells how to load the routine if not already present in memory\n          </li>\n          <li>\n            Either way the stub replaces itself with the address of the routine\n            and executes it\n          </li>\n          <li>\n            All the processes that use language library execute only one copy of\n            the library code\n          </li>\n        </ul>\n        <p>\n          Dynamic loading does not require help from OS. But, dynamic linking\n          does require help from OS because only OS can tell if the required\n          routine is in some other process' memory space\n        </p>\n        <b>Swapping</b>\n        <ul>\n          <li>\n            Swapping of processes in between main memory and backing store(disk)\n          </li>\n          <li>\n            Roll in, roll out : high priority process is brought into memory and\n            lower priority process is sent back to disk\n          </li>\n          <li>Overhead of transfer time</li>\n        </ul>\n        <b>Protection</b>\n        <ul>\n          <li>Memory is contained of OS + user process</li>\n          <li>OS needs to be protected from user process</li>\n          <li>User process needs to be protected from other user process</li>\n          <li>Use relocation(base) and limit register for protection</li>\n          <li>Relocation register contains smallest physical address</li>\n          <li>Limit register contains range of logical addresses</li>\n          <li>\n            When CPU scheduler selects a process for execution, the dispatcher\n            loads the relocation and the limit registers\n          </li>\n          <li>\n            Base {\"<\"}= allowed addresses {\"<\"} base + limit\n          </li>\n        </ul>\n        <hr />\n        <h4>Memory allocation</h4>\n        <ol>\n          <li>\n            <b>Contiguous</b> (external fragmentation issue)\n            <ol>\n              <li>\n                <b>Fixed size partitioning</b>\n                <ul>\n                  <li>\n                    Internal fragmentation can also happen in this approach.\n                  </li>\n                  <li>\n                    Partitions can be different size, but once fixed cannot be\n                    changed.\n                  </li>\n                  <li>Divide memory into fixed partitions</li>\n                  <li>Each partition has one process</li>\n                  <li>\n                    Degree of multiprogramming depends on no. of divisions\n                  </li>\n                  <li>\n                    OS keeps a table to record which parts are free or allocated\n                  </li>\n                  <li>Not used now</li>\n                  <li>Best fit performs best</li>\n                </ul>\n              </li>\n              <li>\n                <b>Variable size partitioning</b>\n                <ul>\n                  <li>\n                    Partitions are not made initially and can change based on\n                    process req.\n                  </li>\n                  <li>Memory is considered as one big hole</li>\n                  <li>\n                    When new process arrives a we find a hole large enough to\n                    accommodate it\n                  </li>\n                  <li>The process occupies only as much space as it needs</li>\n                  <li>Worst fit performs best generally</li>\n                </ul>\n                <b>Algorithms</b>\n                <ol>\n                  <li>\n                    <b>First fit</b> (better and faster)\n                    <ul>\n                      <li>Allocate it to first hole that is big enough</li>\n                    </ul>\n                  </li>\n                  <li>\n                    <b>Best fit</b>\n                    <ul>\n                      <li>Allocate to smallest hole that is big enough</li>\n                    </ul>\n                  </li>\n                  <li>\n                    <b>Worst fit</b> (not as good as above two)\n                    <ul>\n                      <li>allocates to largest hole</li>\n                    </ul>\n                  </li>\n                </ol>\n                These algorithms suffer from external fragmentation\n              </li>\n            </ol>\n            <b>Fragmentation</b>\n            <ul>\n              <li>\n                <b>External fragmentation</b> (more major issue)\n                <ul>\n                  <li>\n                    Condition when enough total memory space exists to satisfy a\n                    request, but it is not contiguous.\n                  </li>\n                </ul>\n              </li>\n              <li>\n                <b>Internal fragmentation</b>\n                <ul>\n                  <li>\n                    Allocated memory may be slightly larger than the requested\n                    memory, this size difference is memory internal to a\n                    partition but not being used.\n                  </li>\n                </ul>\n              </li>\n              <li>\n                <b>Compaction (solution)</b>\n                <ul>\n                  <li>\n                    Free memory is combined to form contiguous large block\n                  </li>\n                  <li>\n                    Compaction is not always possible: if relocation is static\n                    and is done at assembly / load time, compaction cannot be\n                    done (a static relocation does not allow contents of memory\n                    to change)\n                  </li>\n                  <li>Simplest compaction algorithm</li>\n                  <li>\n                    Move all processes towards one end of memory, leaving one\n                    large hole of free memory (expensive, lots of overhead)\n                  </li>\n                  <li>\n                    Another solution is to permit the logical address space of a\n                    process to be non-contiguous (paging and segmentation allows\n                    this solution)\n                  </li>\n                </ul>\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>Non-contiguous</b>\n            <ul>\n              <li>Solves external fragmentation</li>\n              <b>Paging</b>\n              <ul>\n                <li>\n                  Paging permits the physical address space of a process to be\n                  non-contiguous\n                </li>\n                <li>\n                  Traditionally support for paging has been handled by hardware\n                </li>\n                <li>\n                  Recent design : the hardware and OS are closely integrated\n                </li>\n                <br />\n                <li>\n                  Physical memory (RAM) is broken into fixed sized blocks called\n                  frames\n                </li>\n                <li>\n                  Logical memory (backing store) is broken into same sized\n                  blocks called pages (processes broken down into pages)\n                </li>\n                <br />\n                <li>\n                  When a process is to be executed, its pages are loaded into\n                  any available memory frame from the backing store\n                </li>\n                <br />\n                <li>\n                  Noncontiguous frames are allocated to each page of the process\n                </li>\n                <li>\n                  The backing store has blocks the same size as the memory\n                  frames\n                </li>\n                <li>\n                  Every address generated by the CPU is divided into two parts:\n                  <ol>\n                    <li>Page number (to index the page table)</li>\n                    <li>Page offset</li>\n                  </ol>\n                </li>\n                <li>\n                  To generate physical address from this logical address, page\n                  table is used\n                </li>\n                <li>Page table is present for every process</li>\n                <li>Page table contains base address of each page in memory</li>\n                <li>\n                  Page table entry points to the frame number in physical memory\n                </li>\n                <li>\n                  An entry in page table corresponding to a page number in\n                  logical memory gives the frame number of the frame where that\n                  page is stored in physical memory (main memory).\n                </li>\n                <li>Base address + offset = physical memory address</li>\n                <li>\n                  The page size defined by hardware is generally of size 2\n                  <sup>n</sup>\n                </li>\n                <br />\n                <li>\n                  Paging scheme has no external fragmentation, but some internal\n                  fragmentation.\n                </li>\n                <li>\n                  A frame table contains entries for each physical page frame,\n                  indicating which are allocated to which pages of which\n                  process.\n                </li>\n                <br />\n                <li>\n                  Hardware support : Most OSs store a page table for each\n                  process\n                </li>\n                <li>\n                  A pointer to the page table is stored in the process control\n                  block\n                </li>\n                <li>\n                  Page table is implemented as a set of dedicated registers\n                </li>\n                <li>But it only works if size of page table is small</li>\n                <li>\n                  Page table is kept in memory and page table base register PTBR\n                  points to the page table\n                </li>\n                <li>Two memory accesses are required to access one byte</li>\n                <li>\n                  To speed up this process TLB (translation lookaside buffer) is\n                  provided (TLB columns -page no., frame no.)\n                </li>\n                <li>\n                  TLB is fast lookup hardware cache (page number to frame number\n                  mapping) if no match of key(page number) is found then only\n                  page table is searched\n                </li>\n                <li>\n                  TLB stores info of pages of a single process, so for every\n                  context switch TLB has to be cleared\n                </li>\n                <li>So many frequent context switch reduces hit ratio</li>\n                <br />\n                <li>\n                  If address if of n-bits then size of memory is 2^n * (size of\n                  location) <br />2<sup>10</sup> - 1K, 2<sup>20</sup> - 1M, 2\n                  <sup>30</sup> - 1G, 2<sup>40</sup> - 1T, 2<sup>50</sup> - 1P\n                </li>\n              </ul>\n            </ul>\n            <b>Protection</b>\n            <ul>\n              <li>\n                Memory protection is achieved by protection bits for each frame\n              </li>\n              <li>These bits are kept in page table</li>\n              <li>\n                Valid-invalid bit used to check if the page being accessed is\n                within the logical address space or not\n              </li>\n              <li>\n                Illegal addresses are trapped by using the valid-invalid bit\n              </li>\n              <li>\n                Page table length register PTLR indicates the length of the page\n                table\n              </li>\n            </ul>\n            <b>Shared pages</b>\n            <ul>\n              <li>It is possible to share common code</li>\n              <li>The code has to be non self modifying code</li>\n              <li>\n                Each process has its own copy of registers and data storage\n              </li>\n            </ul>\n            <b>Structure of page table</b>\n            <ol>\n              <li>\n                <b>Hierarchical page table</b>\n                <ul>\n                  <li>AKA two level paging algorithm</li>\n                  <li>\n                    Known as a forward mapped page table because address\n                    translation works from the outer page table inwards\n                  </li>\n                  <li>\n                    outer page table -{\">\"} inner page table -{\">\"} memory\n                  </li>\n                </ul>\n              </li>\n              <li>\n                <b>Hashed page table</b>\n                <ul>\n                  <li>\n                    Each entry in hash table contains a linked list of elements\n                    that hash to the same location\n                  </li>\n                  <li>\n                    Each element consists of :{\" \"}\n                    <ol>\n                      <li>Virtual page number</li>\n                      <li>Value of mapped page frame</li>\n                      <li>Pointer to the next element in the linked list</li>\n                    </ol>\n                  </li>\n                  <li>\n                    Clustered page table : are similar to hashed page table,\n                    except that each entry in the page table refers to several\n                    pages (useful in case of sparse address space)\n                  </li>\n                </ul>\n              </li>\n              <li>\n                <b>Inverted page table</b>\n                <ul>\n                  <li>One entry for each real page of memory</li>\n                  <li>\n                    Entry consists of the virtual address of the page stored in\n                    the real memory location, with information about the process\n                    that owns that page\n                  </li>\n                  <li>\n                    This decreases memory needed to store each page table, but\n                    increases time needed to search a page (hash table can be\n                    used to address this issue)\n                  </li>\n                </ul>\n              </li>\n              <b>Protection</b>\n              <ul>\n                <li>\n                  Memory protection is achieved by protection bits for each\n                  frame\n                </li>\n                <li>These bits are kept in page table</li>\n                <li>\n                  Valid-invalid bit used to check if the page being accessed is\n                  within the logical address space or not\n                </li>\n                <li>\n                  Illegal addresses are trapped by using the valid-invalid bit\n                </li>\n                <li>\n                  Page table length register PTLR indicates the length of the\n                  page table\n                </li>\n              </ul>\n              <b>Shared pages</b>\n              <ul>\n                <li>It is possible to share common code</li>\n                <li>The code has to be non self modifying code</li>\n                <li>\n                  Each process has its own copy of registers and data storage\n                </li>\n              </ul>\n              <b>Structure of page table</b>\n              <ol>\n                <li>\n                  <b>Hierarchical page table</b>\n                  <ul>\n                    <li>AKA two level paging algorithm</li>\n                    <li>\n                      Known as a forward mapped page table because address\n                      translation works from the outer page table inwards\n                    </li>\n                    <li>\n                      outer page table -{\">\"} inner page table -{\">\"} memory\n                    </li>\n                  </ul>\n                </li>\n                <li>\n                  <b>Hashed page table</b>\n                  <ul>\n                    <li>\n                      Each entry in hash table contains a linked list of\n                      elements that hash to the same location\n                    </li>\n                    <li>\n                      Each element consists of :{\" \"}\n                      <ol>\n                        <li>Virtual page number</li>\n                        <li>Value of mapped page frame</li>\n                        <li>Pointer to the next element in the linked list</li>\n                      </ol>\n                    </li>\n                    <li>\n                      Clustered page table : are similar to hashed page table,\n                      except that each entry in the page table refers to several\n                      pages (useful in case of sparse address space)\n                    </li>\n                  </ul>\n                </li>\n                <li>\n                  <b>Inverted page table</b>\n                  <ul>\n                    <li>One entry for each real page of memory</li>\n                    <li>\n                      Entry consists of the virtual address of the page stored\n                      in the real memory location, with information about the\n                      process that owns that page\n                    </li>\n                    <li>\n                      This decreases memory needed to store each page table, but\n                      increases time needed to search a page (hash table can be\n                      used to address this issue)\n                    </li>\n                  </ul>\n                </li>\n              </ol>\n            </ol>\n            <b>Segmentation</b>\n            <ul>\n              <li>\n                Memory management scheme that supports the user's view of memory\n              </li>\n              <li>Logical addresses space is a collection of segments</li>\n              <li>Segments are main program, routines, stack, symbol table</li>\n              <li>\n                The user specifies each address by a segment name (number) and\n                an offset\n              </li>\n              <li>\n                A segment table maps two-dimensional user-defined address into\n                one-dimensional physical address\n              </li>\n              <li>\n                Each entry of the table has a segment base and segment limit\n              </li>\n            </ul>\n          </li>\n        </ol>\n      </div>\n    ),\n  },\n  {\n    id: 8,\n    title: \"Disk Scheduling\",\n    content: (\n      <div>\n        <h1>Disk Scheduling</h1>\n        <hr />\n        <p>\n          <b>Disk scheduling</b> : in case of multiple IO requests to different\n          tracks, then which order this should be executed is decided by\n          scheduling algorithm.\n        </p>\n        <ul>\n          <li>Circular disk is called platter</li>\n          <li>It rotates around spindle</li>\n          <li>R/W head is attached with disk arm</li>\n          <li>Disk is divided into circular tracks</li>\n          <li>Tracks are divided into sectors</li>\n        </ul>\n        <p>\n          <b>Seek time :</b> time required to move R/W head on to the desired\n          track.\n        </p>\n        <hr />\n        <h4>Scheduling Algorithms</h4>\n        <ol>\n          <li>\n            <b>FCFS</b>\n            <ul>\n              <li>Inefficient</li>\n            </ul>\n          </li>\n          <li>\n            <b>SSTF (shortest seek time first) </b>\n            <ul>\n              <li>Serves request which is closest</li>\n              <li>Efficient (usually optimal)</li>\n              <li>Tie is broken in the direction of head movement</li>\n              <li>\n                Disadvantage overhead to calculate nearest required and\n                starvation possible\n              </li>\n            </ul>\n          </li>\n          <li>\n            <b>SCAN (elevator algorithm)</b>\n            <ul>\n              <li>\n                Scan starts from one end of the disk and moves to other end and\n                services all req. in path\n              </li>\n              <li>\n                On reaching the head it changes the direction and continues\n              </li>\n              <li>No starvation</li>\n              <li>Long wait time for just visited position is required</li>\n            </ul>\n          </li>\n          <li>\n            <b>CSCAN (circular scan)</b>\n            <ul>\n              <li>\n                Scan starts from one end of the disk and moves to other end and\n                services all req. in path\n              </li>\n              <li>\n                On reaching end it reverses direction and reaches the other end\n                NOT servicing any request\n              </li>\n              <li>Then again starts at step 1</li>\n              <li>Provides uniform wait time</li>\n            </ul>\n          </li>\n          <li>\n            <b>LOOK</b>\n            <ul>\n              <li>\n                Same as SCAN but instead of going to the end, it only goes to\n                the last req and change direction\n              </li>\n              <li>Better than SCAN</li>\n              <li>Overhead to find the last required</li>\n            </ul>\n          </li>\n          <li>\n            <b>CLOOK (circular look)</b>\n            <ul>\n              <li>LOOK + CSCAN</li>\n              <li>Will satisfy req. in one direction</li>\n              <li>\n                Only goes to last req. and changes req and again only goes till\n                the first req.\n              </li>\n              <li>More efficient and uniform wait time compared to CSCAN</li>\n              <li>More overhead in calculations</li>\n            </ul>\n          </li>\n        </ol>\n      </div>\n    ),\n  },\n];\n","import React from \"react\";\nimport Index from \"./index\";\nimport Notes from \"./notes\";\nimport { notes } from \"../data/notes-object\";\n\nconst Content = ({ activeNoteID, showNav, handleClick }) => {\n  return (\n    <div\n      className=\"row\"\n      style={\n        showNav\n          ? { width: \"100%\", margin: \"0 auto\", paddingTop: \"15px\" }\n          : { width: \"80%\", margin: \"0 auto\", paddingTop: \"15px\" }\n      }\n    >\n      {!showNav && (\n        <div className=\"col-3\" style={{ borderRight: \"1px solid #eee\" }}>\n          <Index\n            notes={notes}\n            activeNoteID={activeNoteID}\n            handleClick={handleClick}\n          />\n        </div>\n      )}\n      <div className=\"col\">\n        <Notes note={notes[activeNoteID].content} />\n      </div>\n    </div>\n  );\n};\n\nexport default Content;\n","import React, { Component } from \"react\";\nimport Header from \"./header\";\nimport Content from \"./content\";\nimport { notes } from \"../data/notes-object\";\n\nclass Main extends Component {\n  state = { showResponsiveNav: false, activeNoteID: 0 };\n  resize() {\n    let currentShowNav = window.innerWidth < 950;\n    if (currentShowNav !== this.state.showNav) {\n      this.setState({ showResponsiveNav: currentShowNav });\n    }\n  }\n  componentDidMount() {\n    window.addEventListener(\"resize\", this.resize.bind(this));\n    this.resize();\n  }\n\n  componentWillUnmount() {\n    window.removeEventListener(\"resize\", this.resize.bind(this));\n  }\n\n  handleClick = (id) => {\n    this.setState({ activeNoteID: id });\n  };\n\n  render() {\n    return (\n      <div>\n        <Header\n          showNav={this.state.showResponsiveNav}\n          notes={notes}\n          activeNoteID={this.state.activeNoteID}\n          handleClick={this.handleClick}\n        />\n        <Content\n          showNav={this.state.showResponsiveNav}\n          activeNoteID={this.state.activeNoteID}\n          handleClick={this.handleClick}\n        />\n      </div>\n    );\n  }\n}\n\nexport default Main;\n","import React from \"react\";\nimport ReactDOM from \"react-dom\";\nimport \"bootstrap/dist/css/bootstrap.css\";\nimport Main from \"./components/main\";\nimport \"./style.css\";\n\nReactDOM.render(<Main />, document.getElementById(\"root\"));\n"],"sourceRoot":""}